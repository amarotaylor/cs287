{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cs287-T2-part1.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"U2i_v-6fPgin","colab_type":"text"},"cell_type":"markdown","source":["# HW2: Language Modeling - Linear Interpolation, NNLM, LSTM"]},{"metadata":{"id":"0Os4Eo7vPnBK","colab_type":"text"},"cell_type":"markdown","source":["## Setup"]},{"metadata":{"id":"LNkSIrNpOn-o","colab_type":"code","colab":{}},"cell_type":"code","source":["!pip install -q torch torchtext opt_einsum\n","!pip install -qU git+https://github.com/harvardnlp/namedtensor"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oaLXJwajPrXG","colab_type":"code","colab":{}},"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.distributions import Dirichlet\n","from torch.nn.utils import clip_grad_norm_\n","\n","import re\n","import math\n","from collections import Counter\n","from tqdm import tqdm\n","from itertools import islice\n","import numpy as np\n","\n","import torchtext\n","from torchtext.vocab import Vectors\n","from torchtext.data.iterator import BPTTIterator\n","from torchtext.data import Batch, Dataset\n","\n","from namedtensor import ntorch\n","from namedtensor.text import NamedField"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_IxTY2SAPvel","colab_type":"code","colab":{}},"cell_type":"code","source":["# Our input $x$\n","TEXT = NamedField(names=(\"seqlen\",))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AI3eBEUOPv69","colab_type":"code","colab":{}},"cell_type":"code","source":["# Download data\n","!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/input.txt\n","!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/train.5k.txt\n","!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/train.txt\n","!curl -qO https://raw.githubusercontent.com/harvard-ml-courses/cs287-s18/master/HW2/valid.txt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"TsXvGk7LQiqP","colab_type":"code","colab":{}},"cell_type":"code","source":["# Data distributed with the assignment\n","train, val, test = torchtext.datasets.LanguageModelingDataset.splits(\n","    path=\".\", \n","    train=\"train.txt\", validation=\"valid.txt\", test=\"valid.txt\", text_field=TEXT)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FPcCMwshQm3l","colab_type":"code","colab":{}},"cell_type":"code","source":["# Build vocab\n","TEXT.build_vocab(train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VR1p1cciQnND","colab_type":"code","colab":{}},"cell_type":"code","source":["class NamedBpttIterator(BPTTIterator):\n","    def __iter__(self):\n","        text = self.dataset[0].text\n","        TEXT = self.dataset.fields['text']\n","        TEXT.eos_token = None\n","        text = text + ([TEXT.pad_token] * int(math.ceil(len(text) / self.batch_size)\n","                                              * self.batch_size - len(text)))\n","        data = TEXT.numericalize(\n","            [text], device=self.device)\n","        data = (data\n","            .stack((\"seqlen\", \"batch\"), \"flat\")\n","            .split(\"flat\", (\"batch\", \"seqlen\"), batch=self.batch_size)\n","            .transpose(\"seqlen\", \"batch\")\n","        )\n","\n","        dataset = Dataset(examples=self.dataset.examples, fields=[\n","            ('text', TEXT), ('target', TEXT)])\n","        while True:\n","            for i in range(0, len(self) * self.bptt_len, self.bptt_len):\n","                self.iterations += 1\n","                seq_len = min(self.bptt_len, len(data) - i - 1)\n","                yield Batch.fromvars(\n","                    dataset, self.batch_size,\n","                    text = data.narrow(\"seqlen\", i, seq_len),\n","                    target = data.narrow(\"seqlen\", i+1, seq_len),\n","                )\n","                         \n","            if not self.repeat:\n","                return"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mjIdo0QeQqMb","colab_type":"code","colab":{}},"cell_type":"code","source":["# Generate iterators\n","train_iter, val_iter, test_iter = NamedBpttIterator.splits(\n","    (train, val, test), batch_size=20, device=torch.device(\"cuda\"), bptt_len=36, shuffle=True, repeat=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2E-ZQf4tR7XY","colab_type":"text"},"cell_type":"markdown","source":["## Utility functions"]},{"metadata":{"id":"qqrL7o_uR6iM","colab_type":"code","colab":{}},"cell_type":"code","source":["def find_ngrams(input_list, n):\n","  return torch.stack([torch.stack(i) for i in zip(*[input_list[i:] for i in range(n)])])\n","\n","def make_batch_update(batch, n):\n","  X = torch.stack([find_ngrams(batch[i,:], n) for i in range(batch.shape[0])])[:,:-1,:]\n","  y = batch[:,n:]\n","  return X.contiguous().view(X.shape[0]*X.shape[1], -1), y.contiguous().view(y.shape[0]*y.shape[1])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SgcjV4sQUgKt","colab_type":"code","colab":{}},"cell_type":"code","source":["def calc_prob_interpol(s, unigram_counts, bigram_counts, trigram_counts, alpha):\n","  prob = alpha[0] * trigram_counts[s[0:2]][s[2]] / bigram_counts[s[0],s[1]] if bigram_counts[s[0],s[1]] else 0 # w0w1w2 / w0w1\n","  prob += alpha[1] * bigram_counts[s[1],s[2]] / unigram_counts[s[1]] if unigram_counts[s[1]] else 0 # w1w2 / w1\n","  prob += alpha[2] * unigram_counts[s[2]] / torch.sum(unigram_counts)\n","  return prob"],"execution_count":0,"outputs":[]},{"metadata":{"id":"k4Ueq6VZSMK6","colab_type":"code","colab":{}},"cell_type":"code","source":["def calc_ppl_interpol(iterator, unigram_counts, bigram_counts, trigram_counts, alpha):\n","  total_loss = 0\n","  total_words = 0\n","\n","  for b in iter(iterator):\n","    data = m(torch.transpose(b.text.values, dim0=0, dim1=1))\n","    X, y = make_batch_update(data, seq_len)\n","    total_words += X.shape[0]\n","    for i in range(X.shape[0]):\n","      s = X[i]\n","      prob = calc_prob_interpol(s, unigram_counts, bigram_counts, trigram_counts, alpha)\n","      if prob != 0:\n","        total_loss += -torch.log(prob)\n","\n","  return torch.exp(total_loss / total_words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BeGGm2nHVJuw","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_pred_interpol(sentences, unigram_counts, bigram_counts, trigram_counts, alpha):\n","  predictions = []\n","\n","  for i in range(len(sentences)):\n","    probs = {}\n","\n","    for _, k in range(len(unigram_counts)):\n","      s = [TEXT.vocab.stoi[j] for j in sentences[i][8:10]]\n","      s.extend([k])\n","      probs[k] = calc_prob_interpol(s, unigram_counts, bigram_counts, trigram_counts, alpha)\n","\n","    predictions.append([i for i, c in Counter(probs).most_common(20)])\n","\n","    if i % 100 == 0:\n","      print(i, '/', len(sentences))\n","      \n","  return predictions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"E_uWMkstXOq2","colab_type":"code","colab":{}},"cell_type":"code","source":["def calc_ppl_networks(iterator, net, criterion, model, h0=None): # model = {'nnlm', 'lstm'}\n","  total_loss = 0\n","  total_words = 0\n","  total_correct = 0\n","  \n","  for b in iter(iterator):\n","    if model == 'nnlm':\n","      data = m(torch.transpose(b.text.values, dim0=0, dim1=1))\n","      X, y = make_batch_update(data, seq_len)\n","      prob = net(X)\n","      loss = criterion(prob, y).detach()\n","      num_words = X.shape[0]\n","      pred = torch.argmax(prob, dim=1)\n","    elif model == 'lstm':\n","      data = torch.transpose(b.text.values, dim0=0, dim1=1)\n","      X = data[:,:-1]\n","      y = data[:,1:]\n","      prob, _ = net(X, h0)\n","      loss = criterion(prob.transpose(1,2), y).detach()\n","      num_words = X.shape[0] * X.shape[1]\n","      pred = torch.argmax(prob, dim=2)\n","    else:\n","      print('error')\n","    \n","    total_loss += loss\n","    total_words += num_words\n","    total_correct += torch.sum(pred == y).float()\n","    \n","  ppl = torch.exp(total_loss / total_words)\n","  acc = total_correct / total_words\n","\n","  return ppl, acc"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZacUSM39Z3S7","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_pred_networks(sentences, net, model, h0=None):\n","  predictions = []\n","\n","  for i in range(len(sentences)):\n","    s = torch.tensor([TEXT.vocab.stoi[j] for j in sentences[i][6:10]]).cuda()\n","    \n","    if model == 'nnlm':\n","      prob = net(torch.unsqueeze(s, 0))\n","    elif model == 'lstm':\n","      prob, _ = net(torch.unsqueeze(s, 0), h0)\n","    else:\n","      print('error')\n","      \n","    top_idx = torch.squeeze(torch.argsort(prob, descending=True))[:20]\n","    predictions.append([TEXT.vocab.itos[j] for j in top_idx])\n","\n","    if i % 100 == 0:\n","      print(i, '/', len(sentences))\n","      \n","  return predictions"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BLNcTVJHbIxf","colab_type":"code","colab":{}},"cell_type":"code","source":["def repackage_hidden(h):\n","  return tuple(v.detach() for v in h)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7pL8xNKFSFHS","colab_type":"text"},"cell_type":"markdown","source":["## Global variables"]},{"metadata":{"id":"gGrKgVljSEP3","colab_type":"code","colab":{}},"cell_type":"code","source":["seq_len = 3\n","input_size = 10001\n","m = nn.ConstantPad1d((seq_len-1, 0), 1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bYWlK6tWWIgI","colab_type":"code","colab":{}},"cell_type":"code","source":["# load test set\n","sentences = []\n","for i, l in enumerate(open(\"input.txt\"), 1):\n","  sentences.append(re.split(' ', l))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tbcm324SQyWC","colab_type":"text"},"cell_type":"markdown","source":["## Model I: Linear interpolation"]},{"metadata":{"id":"NgodJZ_fQz8F","colab_type":"code","colab":{}},"cell_type":"code","source":["# get unigram counts (vector)\n","n_words = TEXT.vocab.__len__()\n","unigram_count_vector = torch.zeros([n_words, 1], dtype=torch.uint8)\n","\n","for batch in train_iter:\n","  unigram_count_vector[batch.text.values, 0] += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"D1AKtKdDQsEi","colab_type":"code","colab":{}},"cell_type":"code","source":["# get bigram counts (matrix)\n","bigram_counts_mat = torch.zeros([n_words, n_words], dtype=torch.uint8)\n","\n","for batch in train_iter:\n","  for c in range(29): \n","    bigram_counts_mat[batch.text.values[c,:], batch.text.values[c+1,:]] += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"V4aln1JgRkat","colab_type":"code","colab":{}},"cell_type":"code","source":["# get trigram counts (dictionary of vectors)\n","tri_gram = dict()\n","for i,batch in enumerate(train_iter):\n","  for c in range(28):\n","    for i, tup in enumerate(zip(batch.text.values[c,:].cpu().numpy(), batch.text.values[c+1,:].cpu().numpy())):\n","      if tup in tri_gram:\n","        # increase the count\n","        tri_gram[tup][batch.text.values.cpu().numpy()[c+2,i]] += 1\n","      else:\n","        # initalize entry\n","        tri_gram[tup] = torch.zeros([n_words,1], dtype=torch.uint8)\n","        tri_gram[tup][batch.text.values.cpu().numpy()[c+2,i]] += 1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eqxGulc4Rl2H","colab_type":"code","colab":{}},"cell_type":"code","source":["class linear_model(nn.Module):\n","  def __init__(self):\n","    super(linear_model, self).__init__()\n","    self.alpha = nn.Parameter(torch.Tensor(3, 1))\n","  def forward(self, unigram_model, bigram_model, trigram_model):\n","      prob = self.alpha[0] * unigram_model\n","      prob += self.alpha[1] * bigram_model\n","      prob += self.alpha[2] * trigram_model\n","      return prob\n","  def normalize(self):\n","      self.alpha.data = torch.clamp(self.alpha.data,0.0)\n","      self.alpha.data = self.alpha.data / self.alpha.data.sum()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zvrZG3kQRsRJ","colab_type":"code","colab":{}},"cell_type":"code","source":["# optimize alphas\n","model = linear_model()\n","model.cuda()\n","\n","optim = torch.optim.Adam(model.parameters())\n","criterion = torch.nn.NLLLoss()\n","\n","for i, batch in enumerate(train_iter):\n","  if i % 100 == 0:\n","    print(i)\n","  for c in range(28):\n","    loss = torch.tensor(0.0,device='cuda')\n","    for i, tup in enumerate(zip(batch.text.values[c,:].cpu().numpy(),batch.text.values[c+1,:].cpu().numpy())):\n","      loss = torch.tensor(0.0).cuda()\n","      bigram_model = bigram_counts_mat[tup[1],:].float().cuda() / bigram_counts_mat[tup[1],:].float().sum().cuda()\n","      trigram_model = tri_gram[tup].squeeze().float().cuda() / tri_gram[tup].squeeze().float().sum().cuda()\n","      prob = model(unigram_model.squeeze(), bigram_model.squeeze(), trigram_model.squeeze())\n","      loss += criterion(prob.reshape(1,-1), batch.text.values[c+2,i].reshape(-1))\n","    loss.backward()\n","    optim.step()\n","    model.normalize()\n","    optim.zero_grad()\n","    \n","print(model.alpha.data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Wc6VtWU3Rxv5","colab_type":"code","colab":{}},"cell_type":"code","source":["# calc train ppl and val ppl\n","train_ppl = calc_ppl_interpol(train_iter, unigram_count_vector, bigram_counts_matrix, tri_gram, model.alpha.data)\n","print('Train PPL:', train_ppl)\n","\n","val_ppl = calc_ppl_interpol(val_iter, unigram_count_vector, bigram_counts_matrix, tri_gram, model.alpha.data)\n","print('Val PPL:', val_ppl)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Y4mUWlOOWbj3","colab_type":"code","colab":{}},"cell_type":"code","source":["# generate predictions for kaggle\n","predictions = make_pred_interpol(sentences, unigram_count_vector, bigram_counts_matrix, tri_gram, model.alpha.data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Dmi8ypVqWRGp","colab_type":"text"},"cell_type":"markdown","source":["## Model II: NNLM"]},{"metadata":{"id":"YWVq-Ft7Wof_","colab_type":"code","colab":{}},"cell_type":"code","source":["# language modeling with distributed representations\n","class Bennet(torch.nn.Module):\n","  def __init__(self, input_size, embed_size, hidden_size, seq_len):\n","    super(Bennet, self).__init__()\n","    self.embed = nn.Embedding(input_size, embed_size)\n","    self.hidden = nn.Linear(seq_len * embed_size, hidden_size, bias=True)\n","    self.fc = nn.Linear(hidden_size, input_size, bias=True)\n","    \n","  def forward(self, inputs):\n","    x = self.embed(inputs) \n","    x = x.view(x.shape[0], x.shape[1] * x.shape[2])\n","    \n","    y = self.hidden(x) \n","    y = torch.tanh(y) \n","\n","    z = self.hidden(x)\n","    output = self.fc(z) + self.fc(y) \n","\n","    return output"],"execution_count":0,"outputs":[]},{"metadata":{"id":"l2o9vVTzW5Dz","colab_type":"code","colab":{}},"cell_type":"code","source":["# initalize NN, optimizer, loss function\n","embed_size = 60\n","hidden_size = 50\n","seq_len = 4\n","\n","learning_rate = 1e-2\n","num_epochs = 20\n","\n","net = Bennet(input_size, embed_size, hidden_size, seq_len)\n","net.cuda()\n","\n","optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate, weight_decay=1e-3)\n","lr_lambda = lambda t: learning_rate / (1 + t * 1e-7)\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)\n","criterion = torch.nn.CrossEntropyLoss(reduction = 'sum')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QfrIJVxCW8NG","colab_type":"code","colab":{}},"cell_type":"code","source":["# train model\n","for i in range(num_epochs):\n","  scheduler.step()\n","  \n","  for b in iter(train_iter):\n","    optimizer.zero_grad()\n","    data = m(torch.transpose(b.text.values, dim0=0, dim1=1))\n","    X, y = make_batch_update(data, seq_len)\n","    prob = net(X)\n","    loss = criterion(prob, y)\n","    loss.backward()\n","    optimizer.step()\n","  \n","  ppl, acc = calc_ppl_networks(train_iter, net, criterion, 'nnlm')\n","  ppl_val, acc_val = calc_ppl_networks(val_iter, net, criterion, 'nnlm')\n","  print('Epoch: %d, Train PPL: %.4f, Train Acc: %.4f, Val PPL: %.4f, Val Acc: %.4f' % (i, ppl, acc, ppl_val, acc_val))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vbsDs-dvaV7V","colab_type":"code","colab":{}},"cell_type":"code","source":["# generate predictions for kaggle\n","predictions = make_pred_networks(sentences, net, 'nnlm')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IzEKoqGFWRSU","colab_type":"text"},"cell_type":"markdown","source":["## Model II: LSTM"]},{"metadata":{"id":"Lnld5JgdWnE9","colab_type":"code","colab":{}},"cell_type":"code","source":["# LSTM RNN\n","class RNNet(torch.nn.Module):\n","\n","  def __init__(self, input_size, hidden_size, num_layers, dropout=0.5, weight_tie=False, weight_init=0.05):\n","    super(RNNet, self).__init__()\n","    self.emb = torch.nn.Sequential(torch.nn.Embedding(input_size, hidden_size), torch.nn.Dropout(dropout))\n","    self.rnn = torch.nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, num_layers=num_layers, bias=True, batch_first=True, dropout=dropout)\n","    self.lnr = torch.nn.Sequential(torch.nn.Dropout(dropout), torch.nn.Linear(hidden_size, input_size))\n","    \n","    for f in self.parameters():\n","      torch.nn.init.uniform_(f, a=-weight_init, b=weight_init)\n","      \n","    if weight_tie == True:\n","      self.lnr[1].weight.data=self.emb[0].weight.data\n","      \n","  def forward(self, inputs, h0=None):\n","    x = self.emb(inputs) # batch x seqlen x hidden\n","    x, hidden = self.rnn(x, h0) # batch x seqlen x hidden\n","    y = self.lnr(x) # batch x seqlen x vocab\n","    return y, hidden"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FfwkQ043afR2","colab_type":"code","colab":{}},"cell_type":"code","source":["# initalize LSTM RNN, optimizer, loss function\n","hidden_size = 650\n","num_layers = 2\n","dropout = 0.5\n","learning_rate = 1\n","num_epochs = 39\n","\n","net = RNNet(input_size, hidden_size, num_layers, dropout,weight_tie=True)\n","net.cuda()\n","\n","optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n","lr_lambda = lambda t: learning_rate / (1.2**max(t-6,0))\n","scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda, last_epoch=-1)\n","criterion = torch.nn.CrossEntropyLoss(reduction = 'sum')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QB8Jit1fbEh_","colab_type":"code","colab":{}},"cell_type":"code","source":["# run LSTM RNN\n","for i in range(num_epochs):\n","  scheduler.step()\n","  h0 = None\n","\n","  for b in iter(train_iter):\n","    optimizer.zero_grad()\n","    data = torch.transpose(b.text.values, dim0=0, dim1=1)\n","    X = data[:,:-1]\n","    y = data[:,1:]\n","    if X.shape[1] == 35:\n","      prob, h = net(X, h0)\n","      h0 = repackage_hidden(h)\n","      loss = criterion(prob.transpose(1,2), y)\n","      loss.backward()\n","      clip_grad_norm_(net.parameters(), max_norm=5)\n","      optimizer.step()\n","      \n","  ppl, acc = calc_ppl_networks(train_iter, net, criterion, 'lstm', h0)\n","  ppl_val, acc_val = calc_ppl_networks(val_iter, net, criterion, 'lstm', h0)\n","  print('Epoch: %d, Train PPL: %.4f, Train Acc: %.4f, Val PPL: %.4f, Val Acc: %.4f' % (i, ppl, acc, ppl_val, acc_val))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"znzvcxIBcaFi","colab_type":"code","colab":{}},"cell_type":"code","source":["# generate predictions for kaggle\n","predictions = make_pred_networks(sentences, net, 'lstm', h0)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zO6N09aQWRdM","colab_type":"text"},"cell_type":"markdown","source":["## Export predictions"]},{"metadata":{"id":"9A-GNYcEWTLM","colab_type":"code","colab":{}},"cell_type":"code","source":["# mount drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iDtk0FEQWTqE","colab_type":"code","colab":{}},"cell_type":"code","source":["with open(\"/content/gdrive/My Drive/predictions2.txt\", \"w\") as f:\n","  f.write(\"id,word\\n\")\n","  for i, l in enumerate(open(\"input.txt\"), 1):\n","    f.write(\"%d,%s\\n\"%(i, \" \".join(predictions[i-1])))"],"execution_count":0,"outputs":[]}]}