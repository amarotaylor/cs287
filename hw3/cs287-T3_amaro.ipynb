{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 287, Homework 3: Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "torch.__version__\n",
    "from common import *\n",
    "## Setup\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#!pip install --upgrade pip\n",
    "#!pip install -q numpy\n",
    "\n",
    "#!pip install -q torch torchtext spacy opt_einsum\n",
    "#!pip install -qU git+https://github.com/harvardnlp/namedtensor\n",
    "#!python -m spacy download en\n",
    "#!python -m spacy download de\n",
    "\n",
    "# Torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "# Text text processing library and methods for pretrained word embeddings\n",
    "from torchtext import data, datasets\n",
    "# Named Tensor wrappers\n",
    "from namedtensor import ntorch, NamedTensor\n",
    "from namedtensor.text import NamedField\n",
    "import numpy as np\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'src': <namedtensor.text.torch_text.NamedField object at 0x7fd80d7bd048>, 'trg': <namedtensor.text.torch_text.NamedField object at 0x7fd80d7bd0b8>}\n",
      "119076\n",
      "{'src': ['David', 'Gallo', ':', 'Das', 'ist', 'Bill', 'Lange', '.', 'Ich', 'bin', 'Dave', 'Gallo', '.'], 'trg': ['David', 'Gallo', ':', 'This', 'is', 'Bill', 'Lange', '.', 'I', \"'m\", 'Dave', 'Gallo', '.']}\n",
      "[('.', 113253), (',', 67237), ('ist', 24189), ('die', 23778), ('das', 17102), ('der', 15727), ('und', 15622), ('Sie', 15085), ('es', 13197), ('ich', 12946)]\n",
      "Size of German vocab 13353\n",
      "[('.', 113433), (',', 59512), ('the', 46029), ('to', 29177), ('a', 27548), ('of', 26794), ('I', 24887), ('is', 21775), (\"'s\", 20630), ('that', 19814)]\n",
      "Size of English vocab 11560\n",
      "2 3\n",
      "1 0\n"
     ]
    }
   ],
   "source": [
    "# split raw data into tokens\n",
    "import spacy\n",
    "spacy_de = spacy.load('de')\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenize_de(text):\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]\n",
    "\n",
    "# add beginning-of-sentence and end-of-sentence tokens to target\n",
    "BOS_WORD = '<s>'\n",
    "EOS_WORD = '</s>'\n",
    "DE = NamedField(names=('srcSeqlen',), tokenize=tokenize_de)\n",
    "EN = NamedField(names=('trgSeqlen',), tokenize=tokenize_en,\n",
    "                init_token = BOS_WORD, eos_token = EOS_WORD) # only target needs BOS/EOS\n",
    "\n",
    "# download dataset of 200K pairs of sentences\n",
    "# start with MAXLEN = 20\n",
    "MAX_LEN = 20\n",
    "train, val, test = datasets.IWSLT.splits(exts=('.de', '.en'), fields=(DE, EN), \n",
    "                                         filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
    "                                         len(vars(x)['trg']) <= MAX_LEN)\n",
    "print(train.fields)\n",
    "print(len(train))\n",
    "print(vars(train[0]))\n",
    "\n",
    "# WHAT DOES THIS DO?\n",
    "'''src = open(\"valid.src\", \"w\")\n",
    "trg = open(\"valid.trg\", \"w\")\n",
    "for example in val:\n",
    "    print(\" \".join(example.src), file=src)\n",
    "    print(\" \".join(example.trg), file=trg)\n",
    "src.close()\n",
    "trg.close()'''\n",
    "\n",
    "# build vocab, convert words to indices\n",
    "MIN_FREQ = 5\n",
    "DE.build_vocab(train.src, min_freq=MIN_FREQ)\n",
    "EN.build_vocab(train.trg, min_freq=MIN_FREQ)\n",
    "print(DE.vocab.freqs.most_common(10))\n",
    "print(\"Size of German vocab\", len(DE.vocab))\n",
    "print(EN.vocab.freqs.most_common(10))\n",
    "print(\"Size of English vocab\", len(EN.vocab))\n",
    "print(EN.vocab.stoi[\"<s>\"], EN.vocab.stoi[\"</s>\"])\n",
    "\n",
    "print(EN.vocab.stoi[\"<pad>\"], EN.vocab.stoi[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into batches\n",
    "BATCH_SIZE = 100\n",
    "device = torch.device('cuda:0')\n",
    "train_iter, val_iter = data.BucketIterator.splits((train, val), batch_size=BATCH_SIZE, device=device,\n",
    "                                                  repeat=False, sort_key=lambda x: len(x.src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence to Sequence Learning with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- English to French translation, $p \\left( y_1, \\dots, y_{T'} \\ | \\ x_1, \\dots, x_T \\right) = \\prod_{t = 1}^{T'} p \\left( y_t \\ | \\ v, y_1, \\dots, y_{t-1} \\right)$\n",
    "- Each sentence ends in '<EOS\\>', out-of-vocab words denoted '<UNK\\>'\n",
    "- Model specs: \n",
    "    * Input vocabulary of 160,000 and output vocabulary of 80,000\n",
    "    * Deep LSTM to map (encode) input sequence to fixed-len vector\n",
    "    * Another deep LSTM to translate (decode) fixed-len vector to output sequence\n",
    "    * 4 layers per LSTM, 1000 cells per layer, 1000-dimensional word embeddings, softmax over 80,000 words\n",
    "    * Reversing order of words in source (but not target) improved performance\n",
    "        * Each word in the source is far from its corresponding word in the target (large minimal time lag); reversing the source reduces the minimal time lag, thereby allowing backprop to establish communication between source and target more easily\n",
    "- Training specs:\n",
    "    * Initialize all LSTM params $\\sim Unif[-0.08,0.08]$\n",
    "    * SGD w/o momentum, lr = 0.7\n",
    "        * After 5 epochs, halve the lr every half-epoch\n",
    "        * Train for 7.5 epochs\n",
    "    * Batch size = 128; divide gradient by batch size (denoted $g$)\n",
    "    * Hard constraint gradient norm; if $s = ||g||_2 > 5$, set $s = 5$\n",
    "    * Make sure all sentences within a minibatch are roughly the same length\n",
    "- Objective: $max \\frac{1}{|S|} \\sum_{(T,S) \\in \\mathcal{S}} log \\ p(T \\ | \\ S)$, where $\\mathcal{S}$ is the training set\n",
    "- Prediction: $\\hat{T} = argmax \\ p(T \\ | \\ S)$ via beam search, where beam size $B \\in {1,2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 1000\n",
    "num_layers = 4\n",
    "attn_context2trg = attn_RNNet_batched(input_size=len(EN.vocab),hidden_size=context_size,num_layers=num_layers)\n",
    "attn_context2trg = attn_context2trg.cuda()\n",
    "attn_context2trg_optimizer = torch.optim.Adam(attn_context2trg.parameters(), lr=1e-3)\n",
    "\n",
    "seq2context = SequenceModel(len(DE.vocab),context_size,num_layers=num_layers)\n",
    "seq2context_optimizer = torch.optim.Adam(seq2context.parameters(), lr=1e-3)\n",
    "seq2context = seq2context.cuda()\n",
    "\n",
    "\n",
    "\n",
    "scheduler_c2t = torch.optim.lr_scheduler.ReduceLROnPlateau(attn_context2trg_optimizer, mode=\"min\", patience=10)\n",
    "scheduler_s2c = torch.optim.lr_scheduler.ReduceLROnPlateau(seq2context_optimizer, mode=\"min\", patience=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Batch: 0, Loss: 117.94963073730469\n",
      "Epoch: 1, Batch: 500, Loss: 53.46437454223633\n",
      "Epoch: 1, Batch: 1000, Loss: 46.156402587890625\n",
      "Epoch: 1, Validation PPL: 30.331417083740234, Validation Loss: 19828.201171875\n",
      "Wrote model!\n",
      "Epoch: 2, Batch: 0, Loss: 47.807926177978516\n",
      "Epoch: 2, Batch: 500, Loss: 47.270999908447266\n",
      "Epoch: 2, Batch: 1000, Loss: 40.655426025390625\n",
      "Epoch: 2, Validation PPL: 14.855280876159668, Validation Loss: 15680.1435546875\n",
      "Wrote model!\n",
      "Epoch: 3, Batch: 0, Loss: 37.606197357177734\n",
      "Epoch: 3, Batch: 500, Loss: 34.138397216796875\n",
      "Epoch: 3, Batch: 1000, Loss: 33.33850860595703\n",
      "Epoch: 3, Validation PPL: 10.77730655670166, Validation Loss: 13815.318359375\n",
      "Wrote model!\n",
      "Epoch: 4, Batch: 0, Loss: 28.068899154663086\n",
      "Epoch: 4, Batch: 500, Loss: 30.637357711791992\n",
      "Epoch: 4, Batch: 1000, Loss: 29.713428497314453\n",
      "Epoch: 4, Validation PPL: 9.428854942321777, Validation Loss: 13038.57421875\n",
      "Wrote model!\n",
      "Epoch: 5, Batch: 0, Loss: 28.630231857299805\n",
      "Epoch: 5, Batch: 500, Loss: 29.348587036132812\n",
      "Epoch: 5, Batch: 1000, Loss: 28.402671813964844\n",
      "Epoch: 5, Validation PPL: 8.790947914123535, Validation Loss: 12631.5009765625\n",
      "Wrote model!\n",
      "Epoch: 6, Batch: 0, Loss: 23.295429229736328\n",
      "Epoch: 6, Batch: 500, Loss: 29.496871948242188\n",
      "Epoch: 6, Batch: 1000, Loss: 28.451759338378906\n",
      "Epoch: 6, Validation PPL: 8.479969024658203, Validation Loss: 12422.2138671875\n",
      "Wrote model!\n",
      "Epoch: 7, Batch: 0, Loss: 24.796043395996094\n",
      "Epoch: 7, Batch: 500, Loss: 22.408761978149414\n",
      "Epoch: 7, Batch: 1000, Loss: 23.91573715209961\n",
      "Epoch: 7, Validation PPL: 8.105297088623047, Validation Loss: 12159.62109375\n",
      "Wrote model!\n",
      "Epoch: 8, Batch: 0, Loss: 23.083091735839844\n"
     ]
    }
   ],
   "source": [
    "best_loss = 1e8\n",
    "for e in range(1,300):\n",
    "    attn_training_loop(e,train_iter,seq2context,attn_context2trg,seq2context_optimizer,attn_context2trg_optimizer,BATCH_SIZE=BATCH_SIZE,context_size=context_size)\n",
    "    loss = attn_validation_loop(e,val_iter,seq2context,attn_context2trg,scheduler_c2t,scheduler_s2c,BATCH_SIZE=BATCH_SIZE,context_size=context_size)\n",
    "    if loss < best_loss:\n",
    "        torch.save(seq2context.state_dict(),'best_seq2seq_withattn_seq2context_big_network_no_unk.pt')\n",
    "        torch.save(attn_context2trg.state_dict(),'best_seq2seq_withattn_context2trg_big_network_no_unk.pt')\n",
    "        best_loss = loss\n",
    "        print('Wrote model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2context_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2context_optimizer = torch.optim.Adam(seq2context.parameters(), lr=1e-3)\n",
    "attn_context2trg_optimizer = torch.optim.Adam(attn_context2trg.parameters(), lr=1e-3)\n",
    "scheduler_c2t = torch.optim.lr_scheduler.ReduceLROnPlateau(attn_context2trg_optimizer, mode=\"min\", patience=4)\n",
    "scheduler_s2c = torch.optim.lr_scheduler.ReduceLROnPlateau(seq2context_optimizer, mode=\"min\", patience=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Loss: 27.17890167236328\n",
      "Epoch: 0, Batch: 500, Loss: 28.94061279296875\n",
      "Epoch: 0, Validation PPL: 9.539901733398438, Validation Loss: 9696.322265625\n",
      "Wrote model!\n",
      "Epoch: 1, Batch: 0, Loss: 28.223543167114258\n",
      "Epoch: 1, Batch: 500, Loss: 47.28041076660156\n",
      "Epoch: 1, Validation PPL: 8.965592384338379, Validation Loss: 9429.4013671875\n",
      "Wrote model!\n",
      "Epoch: 2, Batch: 0, Loss: 27.1455135345459\n",
      "Epoch: 2, Batch: 500, Loss: 26.679922103881836\n",
      "Epoch: 2, Validation PPL: 8.621665954589844, Validation Loss: 9261.2421875\n",
      "Wrote model!\n",
      "Epoch: 3, Batch: 0, Loss: 43.625587463378906\n",
      "Epoch: 3, Batch: 500, Loss: 41.136505126953125\n",
      "Epoch: 3, Validation PPL: 9.451292037963867, Validation Loss: 9656.205078125\n",
      "Epoch: 4, Batch: 0, Loss: 42.23749923706055\n",
      "Epoch: 4, Batch: 500, Loss: 40.912757873535156\n",
      "Epoch: 4, Validation PPL: 9.303613662719727, Validation Loss: 9588.501953125\n",
      "Epoch: 5, Batch: 0, Loss: 41.40532684326172\n",
      "Epoch: 5, Batch: 500, Loss: 25.934093475341797\n",
      "Epoch: 5, Validation PPL: 9.829651832580566, Validation Loss: 9824.94921875\n",
      "Epoch: 6, Batch: 0, Loss: 26.652029037475586\n",
      "Epoch: 6, Batch: 500, Loss: 41.4459114074707\n",
      "Epoch: 6, Validation PPL: 9.207603454589844, Validation Loss: 9543.9072265625\n",
      "Epoch: 7, Batch: 0, Loss: 26.411516189575195\n",
      "Epoch: 7, Batch: 500, Loss: 43.59254455566406\n",
      "Epoch: 7, Validation PPL: 9.364081382751465, Validation Loss: 9616.3525390625\n",
      "Epoch: 8, Batch: 0, Loss: 39.105796813964844\n",
      "Epoch: 8, Batch: 500, Loss: 23.659866333007812\n",
      "Epoch: 8, Validation PPL: 9.564517974853516, Validation Loss: 9707.4013671875\n",
      "Epoch: 9, Batch: 0, Loss: 23.023632049560547\n",
      "Epoch: 9, Batch: 500, Loss: 36.986934661865234\n",
      "Epoch: 9, Validation PPL: 9.721504211425781, Validation Loss: 9777.3896484375\n",
      "Epoch: 10, Batch: 0, Loss: 36.91109085083008\n",
      "Epoch: 10, Batch: 500, Loss: 38.95860290527344\n",
      "Epoch: 10, Validation PPL: 9.609468460083008, Validation Loss: 9727.5576171875\n",
      "Epoch: 11, Batch: 0, Loss: 36.2459602355957\n",
      "Epoch: 11, Batch: 500, Loss: 21.295095443725586\n",
      "Epoch: 11, Validation PPL: 9.692707061767578, Validation Loss: 9764.6357421875\n",
      "Epoch: 12, Batch: 0, Loss: 34.854087829589844\n",
      "Epoch: 12, Batch: 500, Loss: 22.410350799560547\n",
      "Epoch: 12, Validation PPL: 9.631630897521973, Validation Loss: 9737.4609375\n",
      "Epoch: 13, Batch: 0, Loss: 22.246721267700195\n",
      "Epoch: 13, Batch: 500, Loss: 22.454383850097656\n",
      "Epoch: 13, Validation PPL: 9.583861351013184, Validation Loss: 9716.0859375\n",
      "Epoch: 14, Batch: 0, Loss: 24.553386688232422\n",
      "Epoch: 14, Batch: 500, Loss: 23.125185012817383\n",
      "Epoch: 14, Validation PPL: 9.684056282043457, Validation Loss: 9760.796875\n",
      "Epoch: 15, Batch: 0, Loss: 20.352556228637695\n",
      "Epoch: 15, Batch: 500, Loss: 23.11290740966797\n",
      "Epoch: 15, Validation PPL: 9.741578102111816, Validation Loss: 9786.2568359375\n",
      "Epoch: 16, Batch: 0, Loss: 34.63313293457031\n",
      "Epoch: 16, Batch: 500, Loss: 21.1915225982666\n",
      "Epoch: 16, Validation PPL: 9.742545127868652, Validation Loss: 9786.68359375\n",
      "Epoch: 17, Batch: 0, Loss: 37.741912841796875\n",
      "Epoch: 17, Batch: 500, Loss: 36.469459533691406\n",
      "Epoch: 17, Validation PPL: 9.717630386352539, Validation Loss: 9775.67578125\n",
      "Epoch: 18, Batch: 0, Loss: 34.65520477294922\n",
      "Epoch: 18, Batch: 500, Loss: 24.267473220825195\n",
      "Epoch: 18, Validation PPL: 9.74074649810791, Validation Loss: 9785.890625\n",
      "Epoch: 19, Batch: 0, Loss: 34.9918327331543\n",
      "Epoch: 19, Batch: 500, Loss: 22.783370971679688\n",
      "Epoch: 19, Validation PPL: 9.744925498962402, Validation Loss: 9787.734375\n",
      "Epoch: 20, Batch: 0, Loss: 35.86893081665039\n",
      "Epoch: 20, Batch: 500, Loss: 35.945743560791016\n",
      "Epoch: 20, Validation PPL: 9.75825023651123, Validation Loss: 9793.6083984375\n",
      "Epoch: 21, Batch: 0, Loss: 38.757389068603516\n",
      "Epoch: 21, Batch: 500, Loss: 34.25756072998047\n",
      "Epoch: 21, Validation PPL: 9.754446983337402, Validation Loss: 9791.9326171875\n",
      "Epoch: 22, Batch: 0, Loss: 22.37438201904297\n",
      "Epoch: 22, Batch: 500, Loss: 21.696552276611328\n",
      "Epoch: 22, Validation PPL: 9.734833717346191, Validation Loss: 9783.2802734375\n",
      "Epoch: 23, Batch: 0, Loss: 20.884017944335938\n",
      "Epoch: 23, Batch: 500, Loss: 21.078248977661133\n",
      "Epoch: 23, Validation PPL: 9.735857963562012, Validation Loss: 9783.7314453125\n",
      "Epoch: 24, Batch: 0, Loss: 22.145315170288086\n",
      "Epoch: 24, Batch: 500, Loss: 37.564395904541016\n",
      "Epoch: 24, Validation PPL: 9.738394737243652, Validation Loss: 9784.8525390625\n",
      "Epoch: 25, Batch: 0, Loss: 35.363460540771484\n",
      "Epoch: 25, Batch: 500, Loss: 36.45635223388672\n",
      "Epoch: 25, Validation PPL: 9.738580703735352, Validation Loss: 9784.9345703125\n",
      "Epoch: 26, Batch: 0, Loss: 21.845876693725586\n",
      "Epoch: 26, Batch: 500, Loss: 35.975833892822266\n",
      "Epoch: 26, Validation PPL: 9.739239692687988, Validation Loss: 9785.2255859375\n",
      "Epoch: 27, Batch: 0, Loss: 35.14292907714844\n",
      "Epoch: 27, Batch: 500, Loss: 32.69794845581055\n",
      "Epoch: 27, Validation PPL: 9.738852500915527, Validation Loss: 9785.0537109375\n",
      "Epoch: 28, Batch: 0, Loss: 21.276840209960938\n",
      "Epoch: 28, Batch: 500, Loss: 34.201011657714844\n",
      "Epoch: 28, Validation PPL: 9.738849639892578, Validation Loss: 9785.052734375\n",
      "Epoch: 29, Batch: 0, Loss: 36.185455322265625\n",
      "Epoch: 29, Batch: 500, Loss: 22.760303497314453\n",
      "Epoch: 29, Validation PPL: 9.738823890686035, Validation Loss: 9785.0419921875\n",
      "Epoch: 30, Batch: 0, Loss: 35.932987213134766\n",
      "Epoch: 30, Batch: 500, Loss: 35.37208557128906\n",
      "Epoch: 30, Validation PPL: 9.738970756530762, Validation Loss: 9785.1064453125\n",
      "Epoch: 31, Batch: 0, Loss: 20.235788345336914\n",
      "Epoch: 31, Batch: 500, Loss: 22.447893142700195\n",
      "Epoch: 31, Validation PPL: 9.739014625549316, Validation Loss: 9785.1259765625\n",
      "Epoch: 32, Batch: 0, Loss: 37.119930267333984\n",
      "Epoch: 32, Batch: 500, Loss: 22.411733627319336\n",
      "Epoch: 32, Validation PPL: 9.739072799682617, Validation Loss: 9785.1513671875\n",
      "Epoch: 33, Batch: 0, Loss: 22.453859329223633\n",
      "Epoch: 33, Batch: 500, Loss: 32.11357116699219\n",
      "Epoch: 33, Validation PPL: 9.738889694213867, Validation Loss: 9785.0703125\n",
      "Epoch: 34, Batch: 0, Loss: 21.564350128173828\n",
      "Epoch: 34, Batch: 500, Loss: 22.361217498779297\n",
      "Epoch: 34, Validation PPL: 9.738980293273926, Validation Loss: 9785.1103515625\n",
      "Epoch: 35, Batch: 0, Loss: 37.425880432128906\n",
      "Epoch: 35, Batch: 500, Loss: 38.299015045166016\n",
      "Epoch: 35, Validation PPL: 9.738984107971191, Validation Loss: 9785.1123046875\n",
      "Epoch: 36, Batch: 0, Loss: 20.82918930053711\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8267964c58fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_ppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mattn_training_split_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_validation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_c2t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_s2c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mppl\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_ppl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/common.py\u001b[0m in \u001b[0;36mattn_training_split_loop\u001b[0;34m(e, train_iter, seq2context, attn_context2trg, seq2context_optimizer, attn_context2trg_optimizer, BATCH_SIZE, context_size, EN)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m                 \u001b[0mtop_s\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEAM_WIDTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtop_s\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/common.py\u001b[0m in \u001b[0;36mbeam_search\u001b[0;34m(src, attn_seq2context, attn_context2trg, BEAM_WIDTH, BATCH_SIZE, max_len, context_size, EN)\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0mindexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBEAM_WIDTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m                 \u001b[0mindexs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbeam_indicator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             \u001b[0mindexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m             \u001b[0mindexs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_ppl = 1e8\n",
    "for e in range(0,300):\n",
    "    attn_training_split_loop(e,train_iter,seq2context,attn_context2trg,seq2context_optimizer,attn_context2trg_optimizer,EN=EN,context_size=500,BATCH_SIZE=BATCH_SIZE)\n",
    "    ppl = attn_validation_loop(e,val_iter,seq2context,attn_context2trg,scheduler_c2t,scheduler_s2c,BATCH_SIZE=BATCH_SIZE,context_size=500)\n",
    "    if ppl < best_ppl:\n",
    "        torch.save(seq2context.state_dict(),'best_seq2seq_withattn_seq2context_splittrain_top3.pt')\n",
    "        torch.save(attn_context2trg.state_dict(),'best_seq2seq_withattn_context2trg_splittrain_top3.pt')\n",
    "        best_ppl = ppl\n",
    "        print('Wrote model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, Batch: 0, Loss: 26.266517639160156\n",
      "Epoch: 20, Batch: 100, Loss: 27.572736740112305\n",
      "Epoch: 20, Batch: 200, Loss: 24.789466857910156\n",
      "Epoch: 20, Batch: 300, Loss: 4.048263072967529\n",
      "Epoch: 20, Batch: 400, Loss: 26.88125228881836\n",
      "Epoch: 20, Batch: 500, Loss: 3.5436458587646484\n",
      "Epoch: 20, Batch: 600, Loss: 26.24700355529785\n",
      "Epoch: 20, Batch: 700, Loss: 4.560873508453369\n",
      "Epoch: 20, Batch: 800, Loss: 30.419139862060547\n",
      "Epoch: 20, Batch: 900, Loss: 4.189573287963867\n",
      "Epoch: 20, Batch: 1000, Loss: 3.6460113525390625\n",
      "Epoch: 20, Batch: 1100, Loss: 3.338818311691284\n",
      "Epoch: 20, Validation PPL: 11.902926445007324, Validation Loss: 14870.6123046875\n",
      "Epoch: 21, Batch: 0, Loss: 3.9499988555908203\n",
      "Epoch: 21, Batch: 100, Loss: 3.9464218616485596\n",
      "Epoch: 21, Batch: 200, Loss: 2.8606319427490234\n",
      "Epoch: 21, Batch: 300, Loss: 3.382117986679077\n",
      "Epoch: 21, Batch: 400, Loss: 25.091960906982422\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-85c9f7fcd385>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#best_ppl = 1e8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mattn_training_split_loop_top_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mppl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_validation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_c2t\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler_s2c\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mppl\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_ppl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/common.py\u001b[0m in \u001b[0;36mattn_training_split_loop_top_3\u001b[0;34m(e, train_iter, seq2context, attn_context2trg, seq2context_optimizer, attn_context2trg_optimizer, BATCH_SIZE, context_size, EN)\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeam_search_first3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq2context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_context2trg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBEAM_WIDTH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cs287/hw3/common.py\u001b[0m in \u001b[0;36mbeam_search_first3\u001b[0;34m(encoder_outputs, encoder_hidden, attn_seq2context, attn_context2trg, BEAM_WIDTH, BATCH_SIZE, max_len, context_size, EN)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_attention\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_context2trg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0mnext_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlsm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mBEAM_WIDTH\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m     \u001b[0mp_words_init\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0mp_words_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp_words_init\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBEAM_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEAM_WIDTH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEAM_WIDTH\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/functional.py\u001b[0m in \u001b[0;36margsort\u001b[0;34m(input, dim, descending)\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescending\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#best_ppl = 1e8\n",
    "for e in range(20,300):\n",
    "    attn_training_split_loop_top_3(e,train_iter,seq2context,attn_context2trg,seq2context_optimizer,attn_context2trg_optimizer,BATCH_SIZE=BATCH_SIZE,context_size=context_size,EN=EN)\n",
    "    ppl = attn_validation_loop(e,val_iter,seq2context,attn_context2trg,scheduler_c2t,scheduler_s2c,BATCH_SIZE=BATCH_SIZE,context_size=context_size)\n",
    "    if ppl < best_ppl:\n",
    "        torch.save(seq2context.state_dict(),'best_seq2seq_withattn_seq2context_splittrain_3.6.pt')\n",
    "        torch.save(attn_context2trg.state_dict(),'best_seq2seq_withattn_context2trg_splittrain_3.6.pt')\n",
    "        best_ppl = ppl\n",
    "        print('Wrote model!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "   seq2context_optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2context.train()\n",
    "attn_context2trg.train()\n",
    "for ix,batch in enumerate(train_iter):\n",
    "        src = batch.src.values.transpose(0,1)\n",
    "        src = reverse_sequence(src)\n",
    "        trg = batch.trg.values.transpose(0,1)\n",
    "        break\n",
    "        if trg.shape[0] == BATCH_SIZE:\n",
    "        \n",
    "            seq2context_optimizer.zero_grad()\n",
    "            attn_context2trg_optimizer.zero_grad()\n",
    "        \n",
    "            encoder_outputs, encoder_hidden = seq2context(src)\n",
    "            loss = 0\n",
    "            decoder_context = torch.zeros(BATCH_SIZE, context_size, device='cuda') # 32 x 500\n",
    "            decoder_hidden = encoder_hidden\n",
    "            sentence = []\n",
    "            for j in range(trg.shape[1] - 1):\n",
    "                word_input = trg[:,j]\n",
    "                decoder_output, decoder_context, decoder_hidden, decoder_attention = attn_context2trg(word_input, decoder_context, decoder_hidden, encoder_outputs)\n",
    "                #print(decoder_output.shape, trg[i,j+1].view(-1).shape)\n",
    "                loss += criterion_train(decoder_output, trg[:,j+1])\n",
    "                \n",
    "                if np.mod(ix,100) == 0:\n",
    "                    sentence.extend([torch.argmax(decoder_output[0,:],dim=0)])\n",
    "                \n",
    "            loss.backward()\n",
    "            seq2context_optimizer.step()\n",
    "            attn_context2trg_optimizer.step()\n",
    "        \n",
    "            if np.mod(ix,500) == 0:\n",
    "                print('Epoch: {}, Batch: {}, Loss: {}'.format(e, ix, loss.cpu().detach()/BATCH_SIZE))\n",
    "                #print([EN.vocab.itos[i] for i in sentence])\n",
    "                #print([EN.vocab.itos[i] for i in trg[0,:]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2context.state_dict(),'best_seq2seq_withattn_seq2context_splittrain_latest.pt')\n",
    "torch.save(attn_context2trg.state_dict(),'best_seq2seq_withattn_context2trg_splittrain_latest.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "update = []\n",
    "for ix,p in enumerate(words):\n",
    "    update.append([torch.stack([p[b]]+([next_words[ix,b]])) for b in range(BEAM_WIDTH)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 42], device='cuda:0')],\n",
       " [tensor([ 2, 27], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 52], device='cuda:0')],\n",
       " [tensor([ 2, 14], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 97], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([ 2, 27], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 24], device='cuda:0')],\n",
       " [tensor([ 2, 27], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([2, 0], device='cuda:0'), tensor([ 2, 14], device='cuda:0')],\n",
       " [tensor([ 2, 14], device='cuda:0'), tensor([ 2, 27], device='cuda:0')],\n",
       " [tensor([ 2, 14], device='cuda:0'), tensor([ 2, 24], device='cuda:0')]]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 5], device='cuda:0')"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_indicator = torch.argsort(p_words_running,dim=1,descending=True)[:,:BEAM_WIDTH]>=2\n",
    "indexs = torch.zeros(BATCH_SIZE,2,device='cuda')\n",
    "for i in range(BATCH_SIZE):\n",
    "    indexs[i,:] += i+(BATCH_SIZE*beam_indicator[i,:].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexs = indexs.long()\n",
    "indexs = indexs.transpose(0,1).flatten()\n",
    "decoder_hidden = tuple([torch.index_select(h,1,indexs) for h in decoder_hidden])\n",
    "decoder_context = torch.index_select(decoder_context,0,indexs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 500])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_words = torch.cat([args[BATCH_SIZE*(b):BATCH_SIZE*(b+1),:] for b in range(BEAM_WIDTH)],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_words = torch.stack([torch.index_select(decoder_output[i,:],-1,next_words[i,:]) for i in range(BATCH_SIZE)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.12301008936547375,\n",
       " 1: 0.1743470876801082,\n",
       " 2: 0.024813375393648696,\n",
       " 3: 0.4313473508338772,\n",
       " 4: 0.7169799087697334,\n",
       " 5: 0.2156059142994965,\n",
       " 6: 0.07298992879668831,\n",
       " 7: 0.8894616281344004,\n",
       " 8: 0.3090598195280607,\n",
       " 9: 0.6069338103608437}"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = []\n",
    "for i in range(10):\n",
    "    items.append(i)\n",
    "    dc[i] = []\n",
    "x = np.random.rand(10)\n",
    "dc.update(dict(zip(items, x)))\n",
    "dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "sentences = []\n",
    "for i, l in enumerate(open(\"source_test.txt\"), 1):\n",
    "    sentences.append(re.split(' ', l))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
