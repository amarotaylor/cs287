{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 287 - HW 4 - Cont."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "from torchtext.vocab import Vectors, GloVe\n",
    "from namedtensor import ntorch, NamedTensor\n",
    "from namedtensor.text import NamedField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train) 549367\n",
      "len(TEXT.vocab) 62998\n",
      "len(LABEL.vocab) 4\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "TEXT = NamedField(names=('seqlen',)) # Our input $x$\n",
    "LABEL = NamedField(sequential=False, names=()) # Our labels $y$\n",
    "train, val, test = torchtext.datasets.SNLI.splits(TEXT, LABEL)\n",
    "print('len(train)', len(train))\n",
    "TEXT.build_vocab(train)\n",
    "LABEL.build_vocab(train)\n",
    "print('len(TEXT.vocab)', len(TEXT.vocab))\n",
    "print('len(LABEL.vocab)', len(LABEL.vocab))\n",
    "train_iter, val_iter, test_iter = torchtext.data.BucketIterator.splits(\n",
    "    (train, val, test), batch_size=16, device=torch.device(\"cuda\"), repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word embeddings shape: OrderedDict([('word', 62998), ('embedding', 300)])\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary with word embeddings\n",
    "# out-of-vocabulary words are hashed to one of 100 random embeddings each initialized to mean 0, stdev 1 (Sec 5.1)\n",
    "unk_vectors = [torch.randn(300) for _ in range(100)]\n",
    "TEXT.vocab.load_vectors(vectors='glove.6B.300d', unk_init=lambda x:random.choice(unk_vectors))\n",
    "vectors = TEXT.vocab.vectors\n",
    "vectors = vectors / vectors.norm(dim=1, keepdim=True) # normalized to have l_2 norm of 1\n",
    "vectors = NamedTensor(vectors, ('word', 'embedding'))\n",
    "TEXT.vocab.vectors = vectors\n",
    "print(\"word embeddings shape:\", TEXT.vocab.vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decomposable Intra-Sentence Attention Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedProject(torch.nn.Module):\n",
    "    def __init__(self, weights, embed_size, project_size):\n",
    "        super(EmbedProject, self).__init__()\n",
    "        self.embed = nn.Embedding.from_pretrained(weights, freeze=True) # weights: input_size x embed_size\n",
    "        self.linear = nn.Linear(embed_size, project_size)\n",
    "        torch.nn.init.normal_(self.linear.weight, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        embedding = self.embed(inputs)\n",
    "        output = self.linear(embedding)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardFIntra(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n",
    "        super(FeedForwardFIntra, self).__init__()\n",
    "        self.d = nn.Dropout(dropout)\n",
    "        self.m = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        for param in self.parameters():\n",
    "            torch.nn.init.normal_(param, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        hidden = self.m(self.linear1(self.d(inputs)))\n",
    "        output = self.m(self.linear2(self.d(hidden)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedDist(torch.nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim): # num = 11, dim = 1\n",
    "        super(EmbedDist, self).__init__()\n",
    "        self.embed = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        torch.nn.init.normal_(self.embed.weight, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        output = self.embed(inputs)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardF(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n",
    "        super(FeedForwardF, self).__init__()\n",
    "        self.d = nn.Dropout(dropout)\n",
    "        self.m = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        for param in self.parameters():\n",
    "            torch.nn.init.normal_(param, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        hidden = self.m(self.linear1(self.d(inputs)))\n",
    "        output = self.m(self.linear2(self.d(hidden)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardG(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n",
    "        super(FeedForwardG, self).__init__()\n",
    "        self.d = nn.Dropout(dropout)\n",
    "        self.m = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        for param in self.parameters():\n",
    "            torch.nn.init.normal_(param, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        hidden = self.m(self.linear1(self.d(inputs)))\n",
    "        output = self.m(self.linear2(self.d(hidden)))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardH(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, dropout=0.2):\n",
    "        super(FeedForwardH, self).__init__()\n",
    "        self.d = nn.Dropout(dropout)\n",
    "        self.m = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)\n",
    "        for param in self.parameters():\n",
    "            torch.nn.init.normal_(param, mean=0, std=0.01)\n",
    "    def forward(self, inputs):\n",
    "        hidden1 = self.m(self.linear1(self.d(inputs)))\n",
    "        hidden2 = self.m(self.linear2(self.d(hidden1)))\n",
    "        output = self.linear3(hidden2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIMENSIONS -- input: 62998, embed: 300, hidden1: 200, hidden2: 400, output: 4\n"
     ]
    }
   ],
   "source": [
    "# dimensions\n",
    "input_size = TEXT.vocab.vectors.shape['word']\n",
    "embed_size = TEXT.vocab.vectors.shape['embedding']\n",
    "hidden_size1 = 200\n",
    "hidden_size2 = hidden_size1 * 2\n",
    "output_size = len(LABEL.vocab)\n",
    "print('DIMENSIONS -- input: %d, embed: %d, hidden1: %d, hidden2: %d, output: %d'%(input_size, embed_size, hidden_size1, hidden_size2, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([62998, 300])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-trained embeddings\n",
    "weights = TEXT.vocab.vectors.values.cuda()\n",
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad>: 1 , null: tensor(56690, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "pad_tkn = TEXT.vocab.stoi['<pad>']\n",
    "null_tkn = torch.tensor(TEXT.vocab.stoi['null'], device='cuda')\n",
    "print('<pad>:', pad_tkn, ', null:', null_tkn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[LABEL.vocab.itos[i] for i in [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[TEXT.vocab.itos[i] for i in [0,1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking to make sure no <unk> labels\n",
    "total = 0\n",
    "for batch in iter(train_iter):\n",
    "    total += torch.sum(batch.label.values == 0)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no prepend with NULL!\n",
    "for batch in iter(train_iter):\n",
    "    print([TEXT.vocab.itos[i] for i in batch.premise.values[:,0]])\n",
    "    print([TEXT.vocab.itos[i] for i in batch.hypothesis.values[:,0]])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.vocab.stoi['null']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedProject(\n",
       "  (embed): Embedding(62998, 300)\n",
       "  (linear): Linear(in_features=300, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EP1 = EmbedProject(weights, embed_size, hidden_size1).cuda()\n",
    "EP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardFIntra(\n",
       "  (d): Dropout(p=0.2)\n",
       "  (m): ReLU()\n",
       "  (linear1): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FI1 = FeedForwardFIntra(hidden_size1, hidden_size1, hidden_size1).cuda()\n",
    "FI1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbedDist(\n",
       "  (embed): Embedding(11, 1)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ED1 = EmbedDist(dist + 1, 1).cuda()\n",
    "ED1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardF(\n",
       "  (d): Dropout(p=0.2)\n",
       "  (m): ReLU()\n",
       "  (linear1): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1 = FeedForwardF(hidden_size2, hidden_size1, hidden_size1).cuda()\n",
    "F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardG(\n",
       "  (d): Dropout(p=0.2)\n",
       "  (m): ReLU()\n",
       "  (linear1): Linear(in_features=800, out_features=200, bias=True)\n",
       "  (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G1 = FeedForwardG(hidden_size2 * 2, hidden_size1, hidden_size1).cuda()\n",
    "G1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeedForwardH(\n",
       "  (d): Dropout(p=0.2)\n",
       "  (m): ReLU()\n",
       "  (linear1): Linear(in_features=400, out_features=200, bias=True)\n",
       "  (linear2): Linear(in_features=200, out_features=200, bias=True)\n",
       "  (linear3): Linear(in_features=200, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H1 = FeedForwardH(hidden_size2, hidden_size1, output_size).cuda()\n",
    "H1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''proj1 = EP1(sent1)\n",
    "proj2 = EP1(sent2)\n",
    "proj1.shape, proj2.shape\n",
    "\n",
    "fi1 = FI1(proj1)\n",
    "fi2 = FI1(proj2)\n",
    "fi1.shape, fi2.shape\n",
    "\n",
    "# intra-sentence attention!\n",
    "score1 = torch.bmm(fi1, fi1.transpose(1,2))\n",
    "score2 = torch.bmm(fi2, fi2.transpose(1,2))\n",
    "score1.shape, score2.shape\n",
    "\n",
    "prob1 = F.softmax(score1, dim=2)\n",
    "prob2 = F.softmax(score2, dim=2)\n",
    "prob1.shape, prob2.shape\n",
    "\n",
    "# intra-sentence attention!\n",
    "proj1_soft = torch.bmm(prob1, proj1)\n",
    "proj2_soft = torch.bmm(prob2, proj2)\n",
    "proj1_soft.shape, proj2_soft.shape\n",
    "\n",
    "# intra-sentence attention!\n",
    "proj1_intra = torch.cat((proj1, proj1_soft), dim=2)\n",
    "proj2_intra = torch.cat((proj2, proj2_soft), dim=2)\n",
    "proj1_intra.shape, proj2_intra.shape\n",
    "\n",
    "dist = 10\n",
    "seqlen = score1.shape[2]\n",
    "steps = torch.arange(0, seqlen)\n",
    "mat_steps = steps.repeat(seqlen, 1)\n",
    "flip_steps = torch.flip(steps, [0]).view(-1, 1)\n",
    "idx = torch.min(torch.abs(mat_steps - flip_steps), torch.tensor(dist))\n",
    "ED1(idx).squeeze().shape'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 19]), torch.Size([16, 14]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_sent1 = batch.premise.values.transpose(0,1)\n",
    "raw_sent2 = batch.hypothesis.values.transpose(0,1)\n",
    "raw_sent1.shape, raw_sent2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20]), torch.Size([16, 15]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_tkns = null_tkn.repeat(raw_sent1.shape[0], 1)\n",
    "sent1 = torch.cat((null_tkns, raw_sent1), 1)\n",
    "sent2 = torch.cat((null_tkns, raw_sent2), 1)\n",
    "sent1.shape, sent2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj1 = EP1(sent1)\n",
    "proj2 = EP1(sent2)\n",
    "proj1.shape, proj2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20]), torch.Size([16, 15]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1 = (sent1 == pad_tkn)\n",
    "mask2 = (sent2 == pad_tkn)\n",
    "mask1.shape, mask2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fi1 = FI1(proj1)\n",
    "fi2 = FI1(proj2)\n",
    "fi1.shape, fi2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 20]), torch.Size([16, 15, 15]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = torch.bmm(fi1, fi1.transpose(1,2))\n",
    "score2 = torch.bmm(fi2, fi2.transpose(1,2))\n",
    "score1.shape, score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 20]), torch.Size([16, 15, 15]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 += get_dist_bias(score1.shape[2], dist, ED1)\n",
    "score2 += get_dist_bias(score2.shape[2], dist, ED1)\n",
    "score1.shape, score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 20]), torch.Size([16, 15, 15]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1c = mask1.unsqueeze(1).expand(-1, sent1.shape[1], -1).float()\n",
    "mask2c = mask2.unsqueeze(1).expand(-1, sent2.shape[1], -1).float()\n",
    "mask1c.shape, mask2c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 20]), torch.Size([16, 15, 15]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = score1 * (1 - mask1c) + (mask1c * -1e8)\n",
    "score2 = score2 * (1 - mask2c) + (mask2c * -1e8)\n",
    "score1.shape, score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 20]), torch.Size([16, 15, 15]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1 = F.softmax(score1, dim=2)\n",
    "prob2 = F.softmax(score2, dim=2)\n",
    "prob1.shape, prob2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj1_soft = torch.bmm(prob1, proj1)\n",
    "proj2_soft = torch.bmm(prob2, proj2)\n",
    "proj1_soft.shape, proj2_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 400]), torch.Size([16, 15, 400]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj1 = torch.cat((proj1, proj1_soft), dim=2)\n",
    "proj2 = torch.cat((proj2, proj2_soft), dim=2) \n",
    "proj1.shape, proj2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = F1(proj1)\n",
    "f2 = F1(proj2)\n",
    "f1.shape, f2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 15]), torch.Size([16, 15, 20]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = torch.bmm(f1, f2.transpose(1,2))\n",
    "score2 = torch.bmm(f2, f1.transpose(1,2))\n",
    "score1.shape, score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 15, 20]), torch.Size([16, 20, 15]))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1a = mask1.unsqueeze(1).expand(-1, sent2.shape[1], -1).float()\n",
    "mask2a = mask2.unsqueeze(1).expand(-1, sent1.shape[1], -1).float()\n",
    "mask1a.shape, mask2a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 15]), torch.Size([16, 15, 20]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score1 = score1 * (1 - mask2a) + (mask2a * -1e8)\n",
    "score2 = score2 * (1 - mask1a) + (mask1a * -1e8)\n",
    "score1.shape, score2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 15]), torch.Size([16, 15, 20]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1 = F.softmax(score1, dim=2)\n",
    "prob2 = F.softmax(score2, dim=2)\n",
    "prob1.shape, prob2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 15, 400]), torch.Size([16, 20, 400]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj1_soft = torch.bmm(prob2, proj1)\n",
    "proj2_soft = torch.bmm(prob1, proj2)\n",
    "proj1_soft.shape, proj2_soft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 800]), torch.Size([16, 15, 800]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proj1_combined = torch.cat((proj1, proj2_soft), dim=2)\n",
    "proj2_combined = torch.cat((proj2, proj1_soft), dim=2)\n",
    "proj1_combined.shape, proj2_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = G1(proj1_combined)\n",
    "g2 = G1(proj2_combined)\n",
    "g1.shape, g2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask1b = mask1.unsqueeze(2).expand(-1, -1, hidden_size1).float()\n",
    "mask2b = mask2.unsqueeze(2).expand(-1, -1, hidden_size1).float()\n",
    "mask1b.shape, mask2b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 20, 200]), torch.Size([16, 15, 200]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1 = g1 * (1 - mask1b)\n",
    "g2 = g2 * (1 - mask2b)\n",
    "g1.shape, g2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([16, 200]), torch.Size([16, 200]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g1_sum = g1.sum(dim=1)\n",
    "g2_sum = g2.sum(dim=1)\n",
    "g1_sum.shape, g2_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 400])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_all = torch.cat((g1_sum, g2_sum), dim=1)\n",
    "g_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 4])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_all = H1(g_all)\n",
    "h_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_bias(seqlen, dist, ED1):\n",
    "    steps = torch.arange(0, seqlen)\n",
    "    mat_steps = steps.repeat(seqlen, 1)\n",
    "    flip_steps = torch.flip(steps, [0]).view(-1, 1)\n",
    "    idx = torch.min(torch.abs(mat_steps - flip_steps), torch.tensor(dist)).cuda()\n",
    "    return ED1(idx).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(sent1, sent2, EP1, F1, G1, H1, intra, dist, FI1, ED1):\n",
    "    proj1 = EP1(sent1)\n",
    "    proj2 = EP1(sent2)\n",
    "    \n",
    "    mask1 = (sent1 == pad_tkn)\n",
    "    mask2 = (sent2 == pad_tkn)\n",
    "        \n",
    "    if intra:\n",
    "        fi1 = FI1(proj1)\n",
    "        fi2 = FI1(proj2)\n",
    "        score1 = torch.bmm(fi1, fi1.transpose(1,2))\n",
    "        score2 = torch.bmm(fi2, fi2.transpose(1,2))\n",
    "        score1 += get_dist_bias(score1.shape[2], dist, ED1)\n",
    "        score2 += get_dist_bias(score2.shape[2], dist, ED1)\n",
    "        mask1c = mask1.unsqueeze(1).expand(-1, sent1.shape[1], -1).float()\n",
    "        mask2c = mask2.unsqueeze(1).expand(-1, sent2.shape[1], -1).float()\n",
    "        score1 = score1 * (1 - mask1c) + (mask1c * -1e8)\n",
    "        score2 = score2 * (1 - mask2c) + (mask2c * -1e8)\n",
    "        prob1 = F.softmax(score1, dim=2)\n",
    "        prob2 = F.softmax(score2, dim=2)\n",
    "        proj1_soft = torch.bmm(prob1, proj1)\n",
    "        proj2_soft = torch.bmm(prob2, proj2)\n",
    "        proj1 = torch.cat((proj1, proj1_soft), dim=2)\n",
    "        proj2 = torch.cat((proj2, proj2_soft), dim=2) \n",
    "        \n",
    "    f1 = F1(proj1)\n",
    "    f2 = F1(proj2)\n",
    "    \n",
    "    score1 = torch.bmm(f1, f2.transpose(1,2))\n",
    "    score2 = torch.bmm(f2, f1.transpose(1,2))\n",
    "    mask1a = mask1.unsqueeze(1).expand(-1, sent2.shape[1], -1).float()\n",
    "    mask2a = mask2.unsqueeze(1).expand(-1, sent1.shape[1], -1).float()\n",
    "    score1 = score1 * (1 - mask2a) + (mask2a * -1e8)\n",
    "    score2 = score2 * (1 - mask1a) + (mask1a * -1e8)\n",
    "    \n",
    "    prob1 = F.softmax(score1, dim=2)\n",
    "    prob2 = F.softmax(score2, dim=2)\n",
    "    proj1_soft = torch.bmm(prob2, proj1)\n",
    "    proj2_soft = torch.bmm(prob1, proj2)\n",
    "    proj1_combined = torch.cat((proj1, proj2_soft), dim=2)\n",
    "    proj2_combined = torch.cat((proj2, proj1_soft), dim=2)\n",
    "    \n",
    "    g1 = G1(proj1_combined)\n",
    "    g2 = G1(proj2_combined)\n",
    "    mask1b = mask1.unsqueeze(2).expand(-1, -1, hidden_size1).float()\n",
    "    mask2b = mask2.unsqueeze(2).expand(-1, -1, hidden_size1).float()\n",
    "    g1 = g1 * (1 - mask1b)\n",
    "    g2 = g2 * (1 - mask2b)\n",
    "    \n",
    "    g1_sum = g1.sum(dim=1)\n",
    "    g2_sum = g2.sum(dim=1)\n",
    "    g_all = torch.cat((g1_sum, g2_sum), dim=1)\n",
    "    h_all = H1(g_all)\n",
    "    return h_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_null(sent):\n",
    "    null_tkns = null_tkn.repeat(sent.shape[0], 1)\n",
    "    return torch.cat((null_tkns, sent), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(e, train_iter, EP1, F1, G1, H1, criterion, optimizer, intra=False, dist=None, FI1=None, ED1=None):\n",
    "    EP1.train()\n",
    "    F1.train()\n",
    "    G1.train()\n",
    "    H1.train()\n",
    "    if intra:\n",
    "        FI1.train()\n",
    "        ED1.train()\n",
    "    \n",
    "    for ix,batch in enumerate(train_iter):\n",
    "        optimizer.zero_grad()\n",
    "        sent1 = prepend_null(batch.premise.values.transpose(0,1))\n",
    "        sent2 = prepend_null(batch.hypothesis.values.transpose(0,1))\n",
    "        target = batch.label.values\n",
    "        output = get_output(sent1, sent2, EP1, F1, G1, H1, intra, dist, FI1, ED1)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if ix % 1000 == 0:\n",
    "            acc = torch.sum(torch.argmax(output, dim=1) == target).item() / target.shape[0]\n",
    "            print('Epoch: {0}, Batch: {1}, Train NLL: {2:0.4f}, Train Acc:{3:0.4f}'.format(e, ix, loss.cpu().detach(), acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(e, val_iter, EP1, F1, G1, H1, criterion, intra=False, dist=None, FI1=None, ED1=None):\n",
    "    EP1.eval()\n",
    "    F1.eval()\n",
    "    G1.eval()\n",
    "    H1.eval()\n",
    "    if intra:\n",
    "        FI1.eval()\n",
    "        ED1.eval()\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_sent = 0\n",
    "    total_correct = 0\n",
    "    \n",
    "    for ix,batch in enumerate(val_iter):\n",
    "        sent1 = prepend_null(batch.premise.values.transpose(0,1))\n",
    "        sent2 = prepend_null(batch.hypothesis.values.transpose(0,1))\n",
    "        target = batch.label.values\n",
    "        output = get_output(sent1, sent2, EP1, F1, G1, H1, intra, dist, FI1, ED1)\n",
    "        \n",
    "        loss = criterion(output, target).item()\n",
    "        sent = sent1.shape[0]\n",
    "        correct = torch.sum(torch.argmax(output, dim=1) == target).item()\n",
    "        \n",
    "        total_loss += loss*sent\n",
    "        total_sent += sent\n",
    "        total_correct += correct\n",
    "    \n",
    "    print('Epoch: {0}, Val NLL: {1:0.4f}, Val Acc: {2:0.4f}'.format(e, total_loss/total_sent, total_correct/total_sent))\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Train NLL: 1.3825, Train Acc:0.2500\n",
      "Epoch: 0, Batch: 1000, Train NLL: 1.0682, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 2000, Train NLL: 1.0618, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 3000, Train NLL: 1.0612, Train Acc:0.3750\n",
      "Epoch: 0, Batch: 4000, Train NLL: 1.1269, Train Acc:0.1875\n",
      "Epoch: 0, Batch: 5000, Train NLL: 1.1323, Train Acc:0.6250\n",
      "Epoch: 0, Batch: 6000, Train NLL: 1.1065, Train Acc:0.2500\n",
      "Epoch: 0, Batch: 7000, Train NLL: 1.0678, Train Acc:0.4375\n",
      "Epoch: 0, Batch: 8000, Train NLL: 0.9472, Train Acc:0.6875\n",
      "Epoch: 0, Batch: 9000, Train NLL: 0.9522, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 10000, Train NLL: 0.9979, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 11000, Train NLL: 1.1684, Train Acc:0.1875\n",
      "Epoch: 0, Batch: 12000, Train NLL: 0.9229, Train Acc:0.6250\n",
      "Epoch: 0, Batch: 13000, Train NLL: 1.0132, Train Acc:0.4375\n",
      "Epoch: 0, Batch: 14000, Train NLL: 1.0711, Train Acc:0.3125\n",
      "Epoch: 0, Batch: 15000, Train NLL: 1.0289, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 16000, Train NLL: 0.9860, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 17000, Train NLL: 0.9463, Train Acc:0.5625\n",
      "Epoch: 0, Batch: 18000, Train NLL: 1.0946, Train Acc:0.4375\n",
      "Epoch: 0, Batch: 19000, Train NLL: 1.1429, Train Acc:0.3750\n",
      "Epoch: 0, Batch: 20000, Train NLL: 0.9831, Train Acc:0.3125\n",
      "Epoch: 0, Batch: 21000, Train NLL: 1.1685, Train Acc:0.3750\n",
      "Epoch: 0, Batch: 22000, Train NLL: 1.1219, Train Acc:0.1875\n",
      "Epoch: 0, Batch: 23000, Train NLL: 0.9647, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 24000, Train NLL: 0.9213, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 25000, Train NLL: 1.1242, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 26000, Train NLL: 1.0392, Train Acc:0.2500\n",
      "Epoch: 0, Batch: 27000, Train NLL: 0.9509, Train Acc:0.5625\n",
      "Epoch: 0, Batch: 28000, Train NLL: 0.7879, Train Acc:0.7500\n",
      "Epoch: 0, Batch: 29000, Train NLL: 0.8973, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 30000, Train NLL: 1.0394, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 31000, Train NLL: 1.0272, Train Acc:0.3750\n",
      "Epoch: 0, Batch: 32000, Train NLL: 0.8207, Train Acc:0.6875\n",
      "Epoch: 0, Batch: 33000, Train NLL: 1.0556, Train Acc:0.5000\n",
      "Epoch: 0, Batch: 34000, Train NLL: 0.8985, Train Acc:0.6250\n",
      "Epoch: 0, Val NLL: 0.9271, Val Acc: 0.5603\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 1, Batch: 0, Train NLL: 0.7666, Train Acc:0.8125\n",
      "Epoch: 1, Batch: 1000, Train NLL: 0.8491, Train Acc:0.5000\n",
      "Epoch: 1, Batch: 2000, Train NLL: 0.8481, Train Acc:0.6250\n",
      "Epoch: 1, Batch: 3000, Train NLL: 0.7165, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 4000, Train NLL: 1.2259, Train Acc:0.3750\n",
      "Epoch: 1, Batch: 5000, Train NLL: 1.0195, Train Acc:0.4375\n",
      "Epoch: 1, Batch: 6000, Train NLL: 0.9208, Train Acc:0.5000\n",
      "Epoch: 1, Batch: 7000, Train NLL: 1.0816, Train Acc:0.3125\n",
      "Epoch: 1, Batch: 8000, Train NLL: 0.8894, Train Acc:0.4375\n",
      "Epoch: 1, Batch: 9000, Train NLL: 0.7537, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 10000, Train NLL: 0.6906, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 11000, Train NLL: 0.9406, Train Acc:0.5000\n",
      "Epoch: 1, Batch: 12000, Train NLL: 0.9054, Train Acc:0.4375\n",
      "Epoch: 1, Batch: 13000, Train NLL: 0.7421, Train Acc:0.8125\n",
      "Epoch: 1, Batch: 14000, Train NLL: 1.0217, Train Acc:0.3750\n",
      "Epoch: 1, Batch: 15000, Train NLL: 1.0227, Train Acc:0.5000\n",
      "Epoch: 1, Batch: 16000, Train NLL: 0.8553, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 17000, Train NLL: 1.1589, Train Acc:0.3750\n",
      "Epoch: 1, Batch: 18000, Train NLL: 1.1267, Train Acc:0.5625\n",
      "Epoch: 1, Batch: 19000, Train NLL: 0.6474, Train Acc:0.7500\n",
      "Epoch: 1, Batch: 20000, Train NLL: 0.6812, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 21000, Train NLL: 1.1039, Train Acc:0.4375\n",
      "Epoch: 1, Batch: 22000, Train NLL: 0.8742, Train Acc:0.6250\n",
      "Epoch: 1, Batch: 23000, Train NLL: 0.7838, Train Acc:0.6875\n",
      "Epoch: 1, Batch: 24000, Train NLL: 0.9159, Train Acc:0.4375\n",
      "Epoch: 1, Batch: 25000, Train NLL: 0.8614, Train Acc:0.5000\n",
      "Epoch: 1, Batch: 26000, Train NLL: 0.7225, Train Acc:0.6250\n",
      "Epoch: 1, Batch: 27000, Train NLL: 0.9534, Train Acc:0.5625\n",
      "Epoch: 1, Batch: 28000, Train NLL: 0.8850, Train Acc:0.5625\n",
      "Epoch: 1, Batch: 29000, Train NLL: 0.7764, Train Acc:0.7500\n",
      "Epoch: 1, Batch: 30000, Train NLL: 0.6895, Train Acc:0.8125\n",
      "Epoch: 1, Batch: 31000, Train NLL: 0.7543, Train Acc:0.6250\n",
      "Epoch: 1, Batch: 32000, Train NLL: 0.9261, Train Acc:0.5625\n",
      "Epoch: 1, Batch: 33000, Train NLL: 0.8333, Train Acc:0.5625\n",
      "Epoch: 1, Batch: 34000, Train NLL: 0.8656, Train Acc:0.6250\n",
      "Epoch: 1, Val NLL: 0.8351, Val Acc: 0.6199\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 2, Batch: 0, Train NLL: 0.8638, Train Acc:0.6250\n",
      "Epoch: 2, Batch: 1000, Train NLL: 0.8308, Train Acc:0.5625\n",
      "Epoch: 2, Batch: 2000, Train NLL: 0.8330, Train Acc:0.7500\n",
      "Epoch: 2, Batch: 3000, Train NLL: 0.6092, Train Acc:0.8750\n",
      "Epoch: 2, Batch: 4000, Train NLL: 0.6784, Train Acc:0.6875\n",
      "Epoch: 2, Batch: 5000, Train NLL: 1.1580, Train Acc:0.4375\n",
      "Epoch: 2, Batch: 18000, Train NLL: 0.9191, Train Acc:0.5625\n",
      "Epoch: 2, Batch: 19000, Train NLL: 0.8687, Train Acc:0.6250\n",
      "Epoch: 2, Batch: 20000, Train NLL: 0.6484, Train Acc:0.8125\n",
      "Epoch: 2, Batch: 21000, Train NLL: 0.8494, Train Acc:0.5625\n",
      "Epoch: 2, Batch: 22000, Train NLL: 0.8204, Train Acc:0.7500\n",
      "Epoch: 2, Batch: 23000, Train NLL: 0.8093, Train Acc:0.7500\n",
      "Epoch: 2, Batch: 24000, Train NLL: 0.9500, Train Acc:0.5625\n",
      "Epoch: 2, Batch: 25000, Train NLL: 0.9703, Train Acc:0.6250\n",
      "Epoch: 2, Batch: 26000, Train NLL: 0.8633, Train Acc:0.4375\n",
      "Epoch: 2, Batch: 27000, Train NLL: 1.0203, Train Acc:0.5000\n",
      "Epoch: 2, Batch: 28000, Train NLL: 0.9227, Train Acc:0.6875\n",
      "Epoch: 2, Batch: 29000, Train NLL: 0.6935, Train Acc:0.6250\n",
      "Epoch: 2, Batch: 30000, Train NLL: 0.8208, Train Acc:0.6875\n",
      "Epoch: 2, Batch: 31000, Train NLL: 0.6664, Train Acc:0.6250\n",
      "Epoch: 2, Batch: 32000, Train NLL: 0.7853, Train Acc:0.5000\n",
      "Epoch: 2, Batch: 33000, Train NLL: 0.3934, Train Acc:0.8750\n",
      "Epoch: 2, Batch: 34000, Train NLL: 0.7439, Train Acc:0.8125\n",
      "Epoch: 2, Val NLL: 0.7814, Val Acc: 0.6517\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 3, Batch: 0, Train NLL: 0.7812, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 1000, Train NLL: 0.7074, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 2000, Train NLL: 0.7688, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 3000, Train NLL: 0.9639, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 4000, Train NLL: 0.7478, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 5000, Train NLL: 1.0916, Train Acc:0.3125\n",
      "Epoch: 3, Batch: 6000, Train NLL: 1.0593, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 7000, Train NLL: 0.6443, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 8000, Train NLL: 0.6814, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 9000, Train NLL: 0.9111, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 10000, Train NLL: 0.6850, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 11000, Train NLL: 0.5984, Train Acc:0.8750\n",
      "Epoch: 3, Batch: 12000, Train NLL: 0.8922, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 13000, Train NLL: 0.9240, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 14000, Train NLL: 0.9664, Train Acc:0.5000\n",
      "Epoch: 3, Batch: 15000, Train NLL: 0.6717, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 16000, Train NLL: 0.8254, Train Acc:0.5000\n",
      "Epoch: 3, Batch: 17000, Train NLL: 0.8329, Train Acc:0.5000\n",
      "Epoch: 3, Batch: 18000, Train NLL: 0.6700, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 19000, Train NLL: 0.8299, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 20000, Train NLL: 1.1681, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 21000, Train NLL: 0.7167, Train Acc:0.6250\n",
      "Epoch: 3, Batch: 22000, Train NLL: 0.9410, Train Acc:0.4375\n",
      "Epoch: 3, Batch: 23000, Train NLL: 0.6953, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 24000, Train NLL: 0.8458, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 25000, Train NLL: 0.8570, Train Acc:0.7500\n",
      "Epoch: 3, Batch: 26000, Train NLL: 0.6586, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 27000, Train NLL: 0.9687, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 28000, Train NLL: 0.8253, Train Acc:0.6250\n",
      "Epoch: 3, Batch: 29000, Train NLL: 0.7424, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 30000, Train NLL: 1.0566, Train Acc:0.5625\n",
      "Epoch: 3, Batch: 31000, Train NLL: 0.9030, Train Acc:0.6875\n",
      "Epoch: 3, Batch: 32000, Train NLL: 0.7349, Train Acc:0.5000\n",
      "Epoch: 3, Batch: 33000, Train NLL: 0.9245, Train Acc:0.5000\n",
      "Epoch: 3, Batch: 34000, Train NLL: 1.2098, Train Acc:0.4375\n",
      "Epoch: 3, Val NLL: 0.7480, Val Acc: 0.6726\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 4, Batch: 0, Train NLL: 0.7633, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 1000, Train NLL: 0.6178, Train Acc:0.9375\n",
      "Epoch: 4, Batch: 2000, Train NLL: 0.8443, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 3000, Train NLL: 0.6851, Train Acc:0.6250\n",
      "Epoch: 4, Batch: 4000, Train NLL: 0.8657, Train Acc:0.5625\n",
      "Epoch: 4, Batch: 5000, Train NLL: 0.9544, Train Acc:0.3750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Batch: 6000, Train NLL: 0.7437, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 7000, Train NLL: 0.8765, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 8000, Train NLL: 1.1986, Train Acc:0.3125\n",
      "Epoch: 4, Batch: 9000, Train NLL: 0.5942, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 10000, Train NLL: 1.0224, Train Acc:0.5625\n",
      "Epoch: 4, Batch: 11000, Train NLL: 0.8691, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 12000, Train NLL: 0.7700, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 13000, Train NLL: 0.4911, Train Acc:0.8125\n",
      "Epoch: 4, Batch: 14000, Train NLL: 0.4845, Train Acc:0.8750\n",
      "Epoch: 4, Batch: 15000, Train NLL: 0.8889, Train Acc:0.6250\n",
      "Epoch: 4, Batch: 16000, Train NLL: 0.6050, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 17000, Train NLL: 0.9947, Train Acc:0.5000\n",
      "Epoch: 4, Batch: 18000, Train NLL: 0.9545, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 19000, Train NLL: 0.6217, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 20000, Train NLL: 0.7094, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 21000, Train NLL: 0.6161, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 22000, Train NLL: 0.5051, Train Acc:0.8125\n",
      "Epoch: 4, Batch: 23000, Train NLL: 0.8404, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 24000, Train NLL: 1.0528, Train Acc:0.5000\n",
      "Epoch: 4, Batch: 25000, Train NLL: 0.9656, Train Acc:0.6250\n",
      "Epoch: 4, Batch: 26000, Train NLL: 0.7572, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 27000, Train NLL: 0.7194, Train Acc:0.6250\n",
      "Epoch: 4, Batch: 28000, Train NLL: 0.7677, Train Acc:0.7500\n",
      "Epoch: 4, Batch: 29000, Train NLL: 0.6323, Train Acc:0.8125\n",
      "Epoch: 4, Batch: 30000, Train NLL: 0.7909, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 31000, Train NLL: 0.8940, Train Acc:0.6875\n",
      "Epoch: 4, Batch: 32000, Train NLL: 0.6192, Train Acc:0.8125\n",
      "Epoch: 4, Batch: 33000, Train NLL: 0.6343, Train Acc:0.8125\n",
      "Epoch: 4, Batch: 34000, Train NLL: 0.8808, Train Acc:0.6250\n",
      "Epoch: 4, Val NLL: 0.7288, Val Acc: 0.6821\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 5, Batch: 0, Train NLL: 0.5464, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 1000, Train NLL: 0.8153, Train Acc:0.6250\n",
      "Epoch: 5, Batch: 2000, Train NLL: 0.7444, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 3000, Train NLL: 0.7037, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 4000, Train NLL: 1.0454, Train Acc:0.4375\n",
      "Epoch: 5, Batch: 5000, Train NLL: 0.6821, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 6000, Train NLL: 0.5375, Train Acc:0.8125\n",
      "Epoch: 5, Batch: 7000, Train NLL: 0.8804, Train Acc:0.5000\n",
      "Epoch: 5, Batch: 8000, Train NLL: 0.8176, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 9000, Train NLL: 0.5290, Train Acc:0.8125\n",
      "Epoch: 5, Batch: 10000, Train NLL: 0.5290, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 11000, Train NLL: 0.6341, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 12000, Train NLL: 0.4970, Train Acc:0.8750\n",
      "Epoch: 5, Batch: 13000, Train NLL: 0.6758, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 14000, Train NLL: 0.5738, Train Acc:0.8125\n",
      "Epoch: 5, Batch: 15000, Train NLL: 0.7198, Train Acc:0.5625\n",
      "Epoch: 5, Batch: 16000, Train NLL: 0.9581, Train Acc:0.5625\n",
      "Epoch: 5, Batch: 17000, Train NLL: 0.6731, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 18000, Train NLL: 0.6768, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 19000, Train NLL: 0.7313, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 20000, Train NLL: 1.0209, Train Acc:0.4375\n",
      "Epoch: 5, Batch: 21000, Train NLL: 0.8434, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 22000, Train NLL: 0.9823, Train Acc:0.6250\n",
      "Epoch: 5, Batch: 23000, Train NLL: 0.5298, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 24000, Train NLL: 0.5939, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 25000, Train NLL: 0.8136, Train Acc:0.6250\n",
      "Epoch: 5, Batch: 26000, Train NLL: 0.8170, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 27000, Train NLL: 0.7444, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 28000, Train NLL: 0.6728, Train Acc:0.6875\n",
      "Epoch: 5, Batch: 29000, Train NLL: 0.7771, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 30000, Train NLL: 0.6494, Train Acc:0.6250\n",
      "Epoch: 5, Batch: 31000, Train NLL: 1.0836, Train Acc:0.4375\n",
      "Epoch: 5, Batch: 32000, Train NLL: 0.6182, Train Acc:0.8125\n",
      "Epoch: 5, Batch: 33000, Train NLL: 0.6295, Train Acc:0.7500\n",
      "Epoch: 5, Batch: 34000, Train NLL: 0.6785, Train Acc:0.6875\n",
      "Epoch: 5, Val NLL: 0.7179, Val Acc: 0.6868\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 6, Batch: 0, Train NLL: 0.7979, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 1000, Train NLL: 0.9122, Train Acc:0.5625\n",
      "Epoch: 6, Batch: 2000, Train NLL: 0.8668, Train Acc:0.5625\n",
      "Epoch: 6, Batch: 3000, Train NLL: 0.5793, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 4000, Train NLL: 0.7289, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 5000, Train NLL: 0.6942, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 6000, Train NLL: 0.6488, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 7000, Train NLL: 0.7968, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 8000, Train NLL: 0.6510, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 9000, Train NLL: 0.5473, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 10000, Train NLL: 0.6760, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 11000, Train NLL: 0.6606, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 12000, Train NLL: 0.5858, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 13000, Train NLL: 0.4601, Train Acc:0.9375\n",
      "Epoch: 6, Batch: 14000, Train NLL: 0.3082, Train Acc:0.9375\n",
      "Epoch: 6, Batch: 15000, Train NLL: 0.7620, Train Acc:0.5625\n",
      "Epoch: 6, Batch: 16000, Train NLL: 0.5096, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 17000, Train NLL: 0.6271, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 18000, Train NLL: 0.4896, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 19000, Train NLL: 0.8955, Train Acc:0.5000\n",
      "Epoch: 6, Batch: 20000, Train NLL: 0.7831, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 21000, Train NLL: 0.7197, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 22000, Train NLL: 0.7943, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 23000, Train NLL: 0.6365, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 24000, Train NLL: 1.0749, Train Acc:0.4375\n",
      "Epoch: 6, Batch: 25000, Train NLL: 0.8621, Train Acc:0.6250\n",
      "Epoch: 6, Batch: 26000, Train NLL: 0.4328, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 27000, Train NLL: 0.6919, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 28000, Train NLL: 0.5938, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 29000, Train NLL: 0.7153, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 30000, Train NLL: 0.9875, Train Acc:0.6250\n",
      "Epoch: 6, Batch: 31000, Train NLL: 0.6014, Train Acc:0.7500\n",
      "Epoch: 6, Batch: 32000, Train NLL: 0.5767, Train Acc:0.8125\n",
      "Epoch: 6, Batch: 33000, Train NLL: 0.7265, Train Acc:0.6875\n",
      "Epoch: 6, Batch: 34000, Train NLL: 0.7605, Train Acc:0.7500\n",
      "Epoch: 6, Val NLL: 0.7024, Val Acc: 0.6987\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 7, Batch: 0, Train NLL: 0.6504, Train Acc:0.8125\n",
      "Epoch: 7, Batch: 1000, Train NLL: 0.4093, Train Acc:0.8125\n",
      "Epoch: 7, Batch: 2000, Train NLL: 0.9435, Train Acc:0.5000\n",
      "Epoch: 7, Batch: 3000, Train NLL: 0.6959, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 4000, Train NLL: 0.7646, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 5000, Train NLL: 0.6668, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 6000, Train NLL: 0.8459, Train Acc:0.5000\n",
      "Epoch: 7, Batch: 7000, Train NLL: 0.5319, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 8000, Train NLL: 0.7108, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 9000, Train NLL: 0.5914, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 10000, Train NLL: 0.8994, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 11000, Train NLL: 0.9350, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 12000, Train NLL: 0.8853, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 13000, Train NLL: 0.8980, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 14000, Train NLL: 0.5225, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 15000, Train NLL: 0.8127, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 16000, Train NLL: 0.7205, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 17000, Train NLL: 0.8734, Train Acc:0.5625\n",
      "Epoch: 7, Batch: 18000, Train NLL: 0.6917, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 19000, Train NLL: 0.5320, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 20000, Train NLL: 0.7229, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 21000, Train NLL: 0.9782, Train Acc:0.5000\n",
      "Epoch: 7, Batch: 22000, Train NLL: 0.3953, Train Acc:1.0000\n",
      "Epoch: 7, Batch: 23000, Train NLL: 0.6215, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 24000, Train NLL: 0.7412, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 25000, Train NLL: 0.6123, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 26000, Train NLL: 0.8352, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 27000, Train NLL: 0.7713, Train Acc:0.6250\n",
      "Epoch: 7, Batch: 28000, Train NLL: 0.9128, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 29000, Train NLL: 0.6495, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 30000, Train NLL: 0.8419, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 31000, Train NLL: 0.5612, Train Acc:0.8125\n",
      "Epoch: 7, Batch: 32000, Train NLL: 0.7237, Train Acc:0.7500\n",
      "Epoch: 7, Batch: 33000, Train NLL: 0.7690, Train Acc:0.6875\n",
      "Epoch: 7, Batch: 34000, Train NLL: 0.6902, Train Acc:0.6875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Val NLL: 0.6942, Val Acc: 0.6990\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 8, Batch: 0, Train NLL: 0.5743, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 1000, Train NLL: 0.5217, Train Acc:0.8750\n",
      "Epoch: 8, Batch: 2000, Train NLL: 1.1333, Train Acc:0.4375\n",
      "Epoch: 8, Batch: 3000, Train NLL: 0.6934, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 4000, Train NLL: 0.7012, Train Acc:0.6250\n",
      "Epoch: 8, Batch: 5000, Train NLL: 0.5562, Train Acc:0.8125\n",
      "Epoch: 8, Batch: 6000, Train NLL: 0.6984, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 7000, Train NLL: 0.6551, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 8000, Train NLL: 0.6037, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 9000, Train NLL: 0.7181, Train Acc:0.6250\n",
      "Epoch: 8, Batch: 10000, Train NLL: 0.4593, Train Acc:0.8750\n",
      "Epoch: 8, Batch: 11000, Train NLL: 0.6422, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 12000, Train NLL: 0.8122, Train Acc:0.6250\n",
      "Epoch: 8, Batch: 13000, Train NLL: 1.0246, Train Acc:0.5000\n",
      "Epoch: 8, Batch: 14000, Train NLL: 0.5933, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 15000, Train NLL: 0.5169, Train Acc:0.8125\n",
      "Epoch: 8, Batch: 16000, Train NLL: 0.6140, Train Acc:0.8125\n",
      "Epoch: 8, Batch: 17000, Train NLL: 1.0078, Train Acc:0.5625\n",
      "Epoch: 8, Batch: 18000, Train NLL: 0.8492, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 19000, Train NLL: 0.9405, Train Acc:0.5000\n",
      "Epoch: 8, Batch: 20000, Train NLL: 0.9180, Train Acc:0.4375\n",
      "Epoch: 8, Batch: 21000, Train NLL: 0.6034, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 22000, Train NLL: 0.8134, Train Acc:0.5625\n",
      "Epoch: 8, Batch: 23000, Train NLL: 0.5226, Train Acc:0.8750\n",
      "Epoch: 8, Batch: 24000, Train NLL: 0.8197, Train Acc:0.6250\n",
      "Epoch: 8, Batch: 25000, Train NLL: 0.8013, Train Acc:0.6250\n",
      "Epoch: 8, Batch: 26000, Train NLL: 0.7329, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 27000, Train NLL: 0.8082, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 28000, Train NLL: 0.5981, Train Acc:0.8125\n",
      "Epoch: 8, Batch: 29000, Train NLL: 0.6764, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 30000, Train NLL: 0.7639, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 31000, Train NLL: 0.4554, Train Acc:0.9375\n",
      "Epoch: 8, Batch: 32000, Train NLL: 0.6819, Train Acc:0.7500\n",
      "Epoch: 8, Batch: 33000, Train NLL: 0.7981, Train Acc:0.6875\n",
      "Epoch: 8, Batch: 34000, Train NLL: 0.9888, Train Acc:0.5625\n",
      "Epoch: 8, Val NLL: 0.6904, Val Acc: 0.7017\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 9, Batch: 0, Train NLL: 0.4539, Train Acc:0.8750\n",
      "Epoch: 9, Batch: 1000, Train NLL: 0.5263, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 2000, Train NLL: 0.8539, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 3000, Train NLL: 1.0424, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 4000, Train NLL: 0.8155, Train Acc:0.6875\n",
      "Epoch: 9, Batch: 5000, Train NLL: 0.5979, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 6000, Train NLL: 0.8986, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 7000, Train NLL: 0.5693, Train Acc:0.8125\n",
      "Epoch: 9, Batch: 8000, Train NLL: 0.7242, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 9000, Train NLL: 0.7092, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 10000, Train NLL: 0.8414, Train Acc:0.5625\n",
      "Epoch: 9, Batch: 11000, Train NLL: 0.5009, Train Acc:0.8125\n",
      "Epoch: 9, Batch: 12000, Train NLL: 0.6937, Train Acc:0.6875\n",
      "Epoch: 9, Batch: 13000, Train NLL: 1.0117, Train Acc:0.5000\n",
      "Epoch: 9, Batch: 14000, Train NLL: 0.8896, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 15000, Train NLL: 0.6326, Train Acc:0.6875\n",
      "Epoch: 9, Batch: 16000, Train NLL: 0.6772, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 17000, Train NLL: 1.3211, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 18000, Train NLL: 0.7733, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 19000, Train NLL: 0.9279, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 20000, Train NLL: 0.9745, Train Acc:0.5625\n",
      "Epoch: 9, Batch: 21000, Train NLL: 0.5368, Train Acc:0.8750\n",
      "Epoch: 9, Batch: 22000, Train NLL: 0.4646, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 23000, Train NLL: 0.5612, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 24000, Train NLL: 0.5276, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 25000, Train NLL: 0.5078, Train Acc:0.8125\n",
      "Epoch: 9, Batch: 26000, Train NLL: 0.4213, Train Acc:0.8125\n",
      "Epoch: 9, Batch: 27000, Train NLL: 0.8572, Train Acc:0.5625\n",
      "Epoch: 9, Batch: 28000, Train NLL: 0.9729, Train Acc:0.5625\n",
      "Epoch: 9, Batch: 29000, Train NLL: 0.8324, Train Acc:0.6875\n",
      "Epoch: 9, Batch: 30000, Train NLL: 0.6144, Train Acc:0.8125\n",
      "Epoch: 9, Batch: 31000, Train NLL: 0.8542, Train Acc:0.6250\n",
      "Epoch: 9, Batch: 32000, Train NLL: 0.6636, Train Acc:0.6875\n",
      "Epoch: 9, Batch: 33000, Train NLL: 0.6708, Train Acc:0.7500\n",
      "Epoch: 9, Batch: 34000, Train NLL: 0.5708, Train Acc:0.8125\n",
      "Epoch: 9, Val NLL: 0.6738, Val Acc: 0.7154\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 10, Batch: 0, Train NLL: 0.6075, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 1000, Train NLL: 0.5370, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 2000, Train NLL: 0.6573, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 3000, Train NLL: 0.6058, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 4000, Train NLL: 0.5846, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 5000, Train NLL: 0.5003, Train Acc:0.8125\n",
      "Epoch: 10, Batch: 6000, Train NLL: 0.8329, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 7000, Train NLL: 0.7482, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 8000, Train NLL: 0.7244, Train Acc:0.6250\n",
      "Epoch: 10, Batch: 9000, Train NLL: 0.7149, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 10000, Train NLL: 0.5588, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 11000, Train NLL: 0.8464, Train Acc:0.6250\n",
      "Epoch: 10, Batch: 12000, Train NLL: 0.8638, Train Acc:0.5000\n",
      "Epoch: 10, Batch: 13000, Train NLL: 0.7357, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 14000, Train NLL: 0.8494, Train Acc:0.6250\n",
      "Epoch: 10, Batch: 15000, Train NLL: 1.4673, Train Acc:0.5000\n",
      "Epoch: 10, Batch: 16000, Train NLL: 0.6258, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 17000, Train NLL: 0.6908, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 18000, Train NLL: 0.4307, Train Acc:0.8750\n",
      "Epoch: 10, Batch: 19000, Train NLL: 0.5904, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 20000, Train NLL: 0.7409, Train Acc:0.6250\n",
      "Epoch: 10, Batch: 21000, Train NLL: 0.6207, Train Acc:0.8125\n",
      "Epoch: 10, Batch: 22000, Train NLL: 0.5467, Train Acc:0.8125\n",
      "Epoch: 10, Batch: 23000, Train NLL: 0.6474, Train Acc:0.6875\n",
      "Epoch: 10, Batch: 24000, Train NLL: 0.9870, Train Acc:0.4375\n",
      "Epoch: 10, Batch: 25000, Train NLL: 0.6825, Train Acc:0.5625\n",
      "Epoch: 10, Batch: 26000, Train NLL: 0.9156, Train Acc:0.5000\n",
      "Epoch: 10, Batch: 27000, Train NLL: 1.0030, Train Acc:0.5000\n",
      "Epoch: 10, Batch: 28000, Train NLL: 0.7280, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 29000, Train NLL: 0.7901, Train Acc:0.5625\n",
      "Epoch: 10, Batch: 30000, Train NLL: 0.5013, Train Acc:0.8125\n",
      "Epoch: 10, Batch: 31000, Train NLL: 0.5423, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 32000, Train NLL: 0.5185, Train Acc:0.7500\n",
      "Epoch: 10, Batch: 33000, Train NLL: 0.7740, Train Acc:0.5625\n",
      "Epoch: 10, Batch: 34000, Train NLL: 0.5712, Train Acc:0.8125\n",
      "Epoch: 10, Val NLL: 0.6684, Val Acc: 0.7203\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 11, Batch: 0, Train NLL: 0.6927, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 1000, Train NLL: 0.7051, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 2000, Train NLL: 0.5340, Train Acc:0.8125\n",
      "Epoch: 11, Batch: 3000, Train NLL: 0.8765, Train Acc:0.6250\n",
      "Epoch: 11, Batch: 4000, Train NLL: 0.4804, Train Acc:0.8125\n",
      "Epoch: 11, Batch: 5000, Train NLL: 0.6229, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 6000, Train NLL: 0.6010, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 7000, Train NLL: 0.6705, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 8000, Train NLL: 0.5942, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 9000, Train NLL: 0.6342, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 10000, Train NLL: 0.6809, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 11000, Train NLL: 0.7318, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 12000, Train NLL: 0.5583, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 13000, Train NLL: 0.7701, Train Acc:0.5000\n",
      "Epoch: 11, Batch: 14000, Train NLL: 1.0134, Train Acc:0.5625\n",
      "Epoch: 11, Batch: 15000, Train NLL: 0.6496, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 16000, Train NLL: 0.8211, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 17000, Train NLL: 0.6762, Train Acc:0.6250\n",
      "Epoch: 11, Batch: 18000, Train NLL: 0.6544, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 19000, Train NLL: 0.4131, Train Acc:0.8750\n",
      "Epoch: 11, Batch: 20000, Train NLL: 1.1318, Train Acc:0.5000\n",
      "Epoch: 11, Batch: 21000, Train NLL: 0.4731, Train Acc:0.8750\n",
      "Epoch: 11, Batch: 22000, Train NLL: 0.8063, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 23000, Train NLL: 0.9549, Train Acc:0.6250\n",
      "Epoch: 11, Batch: 24000, Train NLL: 0.4519, Train Acc:0.8750\n",
      "Epoch: 11, Batch: 25000, Train NLL: 0.7716, Train Acc:0.6250\n",
      "Epoch: 11, Batch: 26000, Train NLL: 0.9520, Train Acc:0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, Batch: 27000, Train NLL: 0.7417, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 28000, Train NLL: 0.8635, Train Acc:0.6875\n",
      "Epoch: 11, Batch: 29000, Train NLL: 0.4487, Train Acc:0.8125\n",
      "Epoch: 11, Batch: 30000, Train NLL: 0.6280, Train Acc:0.8125\n",
      "Epoch: 11, Batch: 31000, Train NLL: 0.5261, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 32000, Train NLL: 0.8044, Train Acc:0.6250\n",
      "Epoch: 11, Batch: 33000, Train NLL: 0.7562, Train Acc:0.7500\n",
      "Epoch: 11, Batch: 34000, Train NLL: 0.3704, Train Acc:0.9375\n",
      "Epoch: 11, Val NLL: 0.6575, Val Acc: 0.7223\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 12, Batch: 0, Train NLL: 0.6526, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 1000, Train NLL: 0.9073, Train Acc:0.3750\n",
      "Epoch: 12, Batch: 2000, Train NLL: 0.3156, Train Acc:0.8750\n",
      "Epoch: 12, Batch: 3000, Train NLL: 0.5001, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 4000, Train NLL: 0.6214, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 5000, Train NLL: 0.5829, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 6000, Train NLL: 0.4710, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 7000, Train NLL: 0.6244, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 8000, Train NLL: 0.8323, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 9000, Train NLL: 0.3955, Train Acc:0.9375\n",
      "Epoch: 12, Batch: 10000, Train NLL: 0.7411, Train Acc:0.6250\n",
      "Epoch: 12, Batch: 11000, Train NLL: 0.8090, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 12000, Train NLL: 0.9979, Train Acc:0.4375\n",
      "Epoch: 12, Batch: 13000, Train NLL: 0.6289, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 14000, Train NLL: 1.0800, Train Acc:0.6250\n",
      "Epoch: 12, Batch: 15000, Train NLL: 0.2880, Train Acc:0.9375\n",
      "Epoch: 12, Batch: 16000, Train NLL: 0.7612, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 17000, Train NLL: 0.4823, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 18000, Train NLL: 0.6062, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 19000, Train NLL: 0.9474, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 20000, Train NLL: 0.7609, Train Acc:0.6250\n",
      "Epoch: 12, Batch: 21000, Train NLL: 0.7422, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 22000, Train NLL: 0.5362, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 23000, Train NLL: 0.5063, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 24000, Train NLL: 0.7287, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 25000, Train NLL: 0.5613, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 26000, Train NLL: 0.5455, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 27000, Train NLL: 0.5293, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 28000, Train NLL: 0.7804, Train Acc:0.7500\n",
      "Epoch: 12, Batch: 29000, Train NLL: 0.7462, Train Acc:0.8125\n",
      "Epoch: 12, Batch: 30000, Train NLL: 0.3976, Train Acc:0.8750\n",
      "Epoch: 12, Batch: 31000, Train NLL: 0.8120, Train Acc:0.6875\n",
      "Epoch: 12, Batch: 32000, Train NLL: 0.6086, Train Acc:0.8750\n",
      "Epoch: 12, Batch: 33000, Train NLL: 0.3909, Train Acc:0.8750\n",
      "Epoch: 12, Batch: 34000, Train NLL: 0.6627, Train Acc:0.6250\n",
      "Epoch: 12, Val NLL: 0.6550, Val Acc: 0.7232\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 13, Batch: 0, Train NLL: 0.6595, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 1000, Train NLL: 0.6248, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 2000, Train NLL: 0.9883, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 3000, Train NLL: 0.7461, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 4000, Train NLL: 0.6509, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 5000, Train NLL: 0.7066, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 6000, Train NLL: 0.5409, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 7000, Train NLL: 0.8510, Train Acc:0.5625\n",
      "Epoch: 13, Batch: 8000, Train NLL: 0.9235, Train Acc:0.6250\n",
      "Epoch: 13, Batch: 9000, Train NLL: 0.4317, Train Acc:0.9375\n",
      "Epoch: 13, Batch: 10000, Train NLL: 0.6091, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 11000, Train NLL: 0.5055, Train Acc:0.8750\n",
      "Epoch: 13, Batch: 12000, Train NLL: 0.4593, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 13000, Train NLL: 0.6332, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 14000, Train NLL: 0.7289, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 15000, Train NLL: 0.9151, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 16000, Train NLL: 0.7118, Train Acc:0.5625\n",
      "Epoch: 13, Batch: 17000, Train NLL: 0.6046, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 18000, Train NLL: 0.7487, Train Acc:0.4375\n",
      "Epoch: 13, Batch: 19000, Train NLL: 0.4848, Train Acc:0.8750\n",
      "Epoch: 13, Batch: 20000, Train NLL: 0.6487, Train Acc:0.6250\n",
      "Epoch: 13, Batch: 21000, Train NLL: 0.7974, Train Acc:0.6250\n",
      "Epoch: 13, Batch: 22000, Train NLL: 0.8795, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 23000, Train NLL: 0.8356, Train Acc:0.5625\n",
      "Epoch: 13, Batch: 24000, Train NLL: 0.6584, Train Acc:0.6250\n",
      "Epoch: 13, Batch: 25000, Train NLL: 0.6314, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 26000, Train NLL: 0.7260, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 27000, Train NLL: 0.5098, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 28000, Train NLL: 0.5060, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 29000, Train NLL: 0.6430, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 30000, Train NLL: 0.6236, Train Acc:0.6875\n",
      "Epoch: 13, Batch: 31000, Train NLL: 0.5413, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 32000, Train NLL: 0.6177, Train Acc:0.7500\n",
      "Epoch: 13, Batch: 33000, Train NLL: 0.6565, Train Acc:0.8125\n",
      "Epoch: 13, Batch: 34000, Train NLL: 0.6605, Train Acc:0.7500\n",
      "Epoch: 13, Val NLL: 0.6548, Val Acc: 0.7240\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 14, Batch: 0, Train NLL: 0.5355, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 1000, Train NLL: 0.7714, Train Acc:0.5625\n",
      "Epoch: 14, Batch: 2000, Train NLL: 0.5775, Train Acc:0.7500\n",
      "Epoch: 14, Batch: 3000, Train NLL: 0.5662, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 4000, Train NLL: 0.9415, Train Acc:0.5625\n",
      "Epoch: 14, Batch: 5000, Train NLL: 0.3982, Train Acc:0.7500\n",
      "Epoch: 14, Batch: 6000, Train NLL: 0.8183, Train Acc:0.6250\n",
      "Epoch: 14, Batch: 7000, Train NLL: 0.4367, Train Acc:0.8750\n",
      "Epoch: 14, Batch: 8000, Train NLL: 0.6140, Train Acc:0.7500\n",
      "Epoch: 14, Batch: 9000, Train NLL: 0.3652, Train Acc:0.9375\n",
      "Epoch: 14, Batch: 10000, Train NLL: 0.5181, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 24000, Train NLL: 0.8851, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 25000, Train NLL: 0.7835, Train Acc:0.6250\n",
      "Epoch: 14, Batch: 26000, Train NLL: 0.5600, Train Acc:0.8750\n",
      "Epoch: 14, Batch: 27000, Train NLL: 0.9035, Train Acc:0.5000\n",
      "Epoch: 14, Batch: 28000, Train NLL: 0.3002, Train Acc:0.8750\n",
      "Epoch: 14, Batch: 29000, Train NLL: 0.7024, Train Acc:0.6875\n",
      "Epoch: 14, Batch: 30000, Train NLL: 0.5918, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 31000, Train NLL: 0.5352, Train Acc:0.8125\n",
      "Epoch: 14, Batch: 32000, Train NLL: 0.7483, Train Acc:0.7500\n",
      "Epoch: 14, Batch: 33000, Train NLL: 0.6647, Train Acc:0.6875\n",
      "Epoch: 14, Batch: 34000, Train NLL: 0.6740, Train Acc:0.6875\n",
      "Epoch: 14, Val NLL: 0.6467, Val Acc: 0.7325\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 15, Batch: 0, Train NLL: 0.5914, Train Acc:0.7500\n",
      "Epoch: 15, Batch: 1000, Train NLL: 0.5605, Train Acc:0.7500\n",
      "Epoch: 15, Batch: 2000, Train NLL: 0.8780, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 3000, Train NLL: 0.5030, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 4000, Train NLL: 0.4999, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 5000, Train NLL: 1.1503, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 6000, Train NLL: 0.8037, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 7000, Train NLL: 0.6952, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 8000, Train NLL: 0.4167, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 9000, Train NLL: 0.9287, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 10000, Train NLL: 0.7658, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 11000, Train NLL: 0.6858, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 12000, Train NLL: 0.7549, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 13000, Train NLL: 0.4545, Train Acc:0.9375\n",
      "Epoch: 15, Batch: 14000, Train NLL: 0.4729, Train Acc:0.9375\n",
      "Epoch: 15, Batch: 15000, Train NLL: 0.6952, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 16000, Train NLL: 0.4107, Train Acc:0.8750\n",
      "Epoch: 15, Batch: 17000, Train NLL: 0.3484, Train Acc:0.8750\n",
      "Epoch: 15, Batch: 18000, Train NLL: 0.6849, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 19000, Train NLL: 0.7466, Train Acc:0.5625\n",
      "Epoch: 15, Batch: 20000, Train NLL: 0.9690, Train Acc:0.5000\n",
      "Epoch: 15, Batch: 21000, Train NLL: 0.6128, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 22000, Train NLL: 0.8274, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 23000, Train NLL: 0.5671, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 24000, Train NLL: 0.2595, Train Acc:0.9375\n",
      "Epoch: 15, Batch: 25000, Train NLL: 0.3035, Train Acc:0.8750\n",
      "Epoch: 15, Batch: 26000, Train NLL: 0.7503, Train Acc:0.6250\n",
      "Epoch: 15, Batch: 27000, Train NLL: 0.4716, Train Acc:0.8750\n",
      "Epoch: 15, Batch: 28000, Train NLL: 0.5453, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 29000, Train NLL: 1.0292, Train Acc:0.5625\n",
      "Epoch: 15, Batch: 30000, Train NLL: 0.6313, Train Acc:0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, Batch: 31000, Train NLL: 0.6076, Train Acc:0.6875\n",
      "Epoch: 15, Batch: 32000, Train NLL: 0.4493, Train Acc:0.8750\n",
      "Epoch: 15, Batch: 33000, Train NLL: 0.5812, Train Acc:0.8125\n",
      "Epoch: 15, Batch: 34000, Train NLL: 0.5834, Train Acc:0.7500\n",
      "Epoch: 15, Val NLL: 0.6428, Val Acc: 0.7298\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 16, Batch: 0, Train NLL: 0.7981, Train Acc:0.6250\n",
      "Epoch: 16, Batch: 1000, Train NLL: 0.9806, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 2000, Train NLL: 0.4446, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 3000, Train NLL: 0.8493, Train Acc:0.6875\n",
      "Epoch: 16, Batch: 4000, Train NLL: 0.4982, Train Acc:0.6875\n",
      "Epoch: 16, Batch: 5000, Train NLL: 0.4137, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 6000, Train NLL: 0.6240, Train Acc:0.8125\n",
      "Epoch: 16, Batch: 7000, Train NLL: 0.5927, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 8000, Train NLL: 0.5110, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 9000, Train NLL: 0.8850, Train Acc:0.5625\n",
      "Epoch: 16, Batch: 10000, Train NLL: 0.4934, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 11000, Train NLL: 0.4201, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 12000, Train NLL: 0.9228, Train Acc:0.5625\n",
      "Epoch: 16, Batch: 13000, Train NLL: 0.7126, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 14000, Train NLL: 0.4730, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 15000, Train NLL: 0.6728, Train Acc:0.6250\n",
      "Epoch: 16, Batch: 16000, Train NLL: 0.4022, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 17000, Train NLL: 0.3518, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 18000, Train NLL: 0.6047, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 19000, Train NLL: 0.8979, Train Acc:0.5625\n",
      "Epoch: 16, Batch: 20000, Train NLL: 0.6449, Train Acc:0.6875\n",
      "Epoch: 16, Batch: 21000, Train NLL: 0.6294, Train Acc:0.6875\n",
      "Epoch: 16, Batch: 22000, Train NLL: 0.5861, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 23000, Train NLL: 0.7566, Train Acc:0.6875\n",
      "Epoch: 16, Batch: 24000, Train NLL: 0.7011, Train Acc:0.4375\n",
      "Epoch: 16, Batch: 25000, Train NLL: 0.8989, Train Acc:0.6250\n",
      "Epoch: 16, Batch: 26000, Train NLL: 0.5779, Train Acc:0.8125\n",
      "Epoch: 16, Batch: 27000, Train NLL: 0.4842, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 28000, Train NLL: 0.7794, Train Acc:0.7500\n",
      "Epoch: 16, Batch: 29000, Train NLL: 1.0929, Train Acc:0.5625\n",
      "Epoch: 16, Batch: 30000, Train NLL: 0.7789, Train Acc:0.6250\n",
      "Epoch: 16, Batch: 31000, Train NLL: 0.5010, Train Acc:0.8125\n",
      "Epoch: 16, Batch: 32000, Train NLL: 1.1465, Train Acc:0.4375\n",
      "Epoch: 16, Batch: 33000, Train NLL: 0.5387, Train Acc:0.8750\n",
      "Epoch: 16, Batch: 34000, Train NLL: 0.7670, Train Acc:0.5625\n",
      "Epoch: 16, Val NLL: 0.6435, Val Acc: 0.7324\n",
      "LR = 0.025\n",
      "Epoch: 17, Batch: 0, Train NLL: 0.7559, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 1000, Train NLL: 0.4665, Train Acc:0.8125\n",
      "Epoch: 17, Batch: 2000, Train NLL: 0.8247, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 3000, Train NLL: 0.8264, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 4000, Train NLL: 0.9893, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 5000, Train NLL: 0.5544, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 6000, Train NLL: 0.5332, Train Acc:0.8125\n",
      "Epoch: 17, Batch: 7000, Train NLL: 0.6217, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 8000, Train NLL: 0.8178, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 9000, Train NLL: 0.5517, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 10000, Train NLL: 0.8180, Train Acc:0.5625\n",
      "Epoch: 17, Batch: 11000, Train NLL: 0.8263, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 12000, Train NLL: 0.8271, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 13000, Train NLL: 0.8074, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 14000, Train NLL: 1.1182, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 15000, Train NLL: 0.4187, Train Acc:0.8125\n",
      "Epoch: 17, Batch: 16000, Train NLL: 0.7311, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 17000, Train NLL: 0.8025, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 18000, Train NLL: 1.0737, Train Acc:0.5625\n",
      "Epoch: 17, Batch: 19000, Train NLL: 0.8554, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 20000, Train NLL: 0.4294, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 21000, Train NLL: 0.6362, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 22000, Train NLL: 0.2400, Train Acc:1.0000\n",
      "Epoch: 17, Batch: 23000, Train NLL: 0.6167, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 24000, Train NLL: 0.6861, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 25000, Train NLL: 0.6175, Train Acc:0.8125\n",
      "Epoch: 17, Batch: 26000, Train NLL: 0.8245, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 27000, Train NLL: 0.5281, Train Acc:0.8125\n",
      "Epoch: 17, Batch: 28000, Train NLL: 0.7137, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 29000, Train NLL: 0.7665, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 30000, Train NLL: 0.5644, Train Acc:0.7500\n",
      "Epoch: 17, Batch: 31000, Train NLL: 0.7771, Train Acc:0.6250\n",
      "Epoch: 17, Batch: 32000, Train NLL: 0.7286, Train Acc:0.6875\n",
      "Epoch: 17, Batch: 33000, Train NLL: 0.4077, Train Acc:0.9375\n",
      "Epoch: 17, Batch: 34000, Train NLL: 0.5639, Train Acc:0.7500\n",
      "Epoch: 17, Val NLL: 0.6325, Val Acc: 0.7371\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 18, Batch: 0, Train NLL: 0.4472, Train Acc:0.8750\n",
      "Epoch: 18, Batch: 1000, Train NLL: 0.4416, Train Acc:0.9375\n",
      "Epoch: 18, Batch: 2000, Train NLL: 0.7738, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 3000, Train NLL: 0.6128, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 4000, Train NLL: 0.7169, Train Acc:0.6250\n",
      "Epoch: 18, Batch: 5000, Train NLL: 0.4868, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 6000, Train NLL: 1.0317, Train Acc:0.5000\n",
      "Epoch: 18, Batch: 7000, Train NLL: 0.7900, Train Acc:0.4375\n",
      "Epoch: 18, Batch: 8000, Train NLL: 0.5709, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 9000, Train NLL: 0.4018, Train Acc:0.9375\n",
      "Epoch: 18, Batch: 10000, Train NLL: 0.2255, Train Acc:1.0000\n",
      "Epoch: 18, Batch: 11000, Train NLL: 1.0165, Train Acc:0.6250\n",
      "Epoch: 18, Batch: 12000, Train NLL: 0.6002, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 13000, Train NLL: 0.8353, Train Acc:0.5000\n",
      "Epoch: 18, Batch: 14000, Train NLL: 0.6047, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 15000, Train NLL: 0.4059, Train Acc:0.8125\n",
      "Epoch: 18, Batch: 16000, Train NLL: 0.8398, Train Acc:0.5625\n",
      "Epoch: 18, Batch: 17000, Train NLL: 0.7387, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 18000, Train NLL: 0.7333, Train Acc:0.6250\n",
      "Epoch: 18, Batch: 19000, Train NLL: 0.3275, Train Acc:0.8750\n",
      "Epoch: 18, Batch: 20000, Train NLL: 0.3086, Train Acc:0.8750\n",
      "Epoch: 18, Batch: 21000, Train NLL: 0.7150, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 22000, Train NLL: 0.8240, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 23000, Train NLL: 0.4917, Train Acc:0.8125\n",
      "Epoch: 18, Batch: 24000, Train NLL: 0.5421, Train Acc:0.8125\n",
      "Epoch: 18, Batch: 25000, Train NLL: 0.3203, Train Acc:0.9375\n",
      "Epoch: 18, Batch: 26000, Train NLL: 0.6045, Train Acc:0.7500\n",
      "Epoch: 18, Batch: 27000, Train NLL: 0.8226, Train Acc:0.5000\n",
      "Epoch: 18, Batch: 28000, Train NLL: 0.4371, Train Acc:0.8750\n",
      "Epoch: 18, Batch: 29000, Train NLL: 0.6027, Train Acc:0.8125\n",
      "Epoch: 18, Batch: 30000, Train NLL: 0.6596, Train Acc:0.6250\n",
      "Epoch: 18, Batch: 31000, Train NLL: 0.6397, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 32000, Train NLL: 0.8266, Train Acc:0.6875\n",
      "Epoch: 18, Batch: 33000, Train NLL: 0.5599, Train Acc:0.8125\n",
      "Epoch: 18, Batch: 34000, Train NLL: 0.5422, Train Acc:0.7500\n",
      "Epoch: 18, Val NLL: 0.6405, Val Acc: 0.7312\n",
      "LR = 0.025\n",
      "Epoch: 19, Batch: 0, Train NLL: 0.5141, Train Acc:0.8125\n",
      "Epoch: 19, Batch: 1000, Train NLL: 0.6607, Train Acc:0.6875\n",
      "Epoch: 19, Batch: 2000, Train NLL: 0.6860, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 3000, Train NLL: 0.6844, Train Acc:0.6250\n",
      "Epoch: 19, Batch: 4000, Train NLL: 0.6141, Train Acc:0.6875\n",
      "Epoch: 19, Batch: 5000, Train NLL: 0.6213, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 6000, Train NLL: 0.7014, Train Acc:0.6875\n",
      "Epoch: 19, Batch: 7000, Train NLL: 0.4874, Train Acc:0.8750\n",
      "Epoch: 19, Batch: 8000, Train NLL: 1.1547, Train Acc:0.5625\n",
      "Epoch: 19, Batch: 9000, Train NLL: 0.5442, Train Acc:0.8750\n",
      "Epoch: 19, Batch: 10000, Train NLL: 0.8222, Train Acc:0.6250\n",
      "Epoch: 19, Batch: 11000, Train NLL: 0.5943, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 12000, Train NLL: 0.6705, Train Acc:0.5625\n",
      "Epoch: 19, Batch: 13000, Train NLL: 0.7234, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 14000, Train NLL: 0.7838, Train Acc:0.6250\n",
      "Epoch: 19, Batch: 15000, Train NLL: 0.7029, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 16000, Train NLL: 0.5562, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 17000, Train NLL: 0.6643, Train Acc:0.5000\n",
      "Epoch: 19, Batch: 18000, Train NLL: 0.7108, Train Acc:0.6250\n",
      "Epoch: 19, Batch: 19000, Train NLL: 0.4896, Train Acc:0.8125\n",
      "Epoch: 19, Batch: 20000, Train NLL: 0.8857, Train Acc:0.5625\n",
      "Epoch: 19, Batch: 21000, Train NLL: 0.4625, Train Acc:0.8125\n",
      "Epoch: 19, Batch: 22000, Train NLL: 0.6653, Train Acc:0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, Batch: 23000, Train NLL: 0.6887, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 24000, Train NLL: 0.7144, Train Acc:0.5625\n",
      "Epoch: 19, Batch: 25000, Train NLL: 0.8779, Train Acc:0.5625\n",
      "Epoch: 19, Batch: 26000, Train NLL: 0.4751, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 27000, Train NLL: 0.4776, Train Acc:0.8750\n",
      "Epoch: 19, Batch: 28000, Train NLL: 0.5124, Train Acc:0.7500\n",
      "Epoch: 19, Batch: 29000, Train NLL: 0.3377, Train Acc:0.9375\n",
      "Epoch: 19, Batch: 30000, Train NLL: 0.6344, Train Acc:0.6875\n",
      "Epoch: 19, Batch: 31000, Train NLL: 0.5938, Train Acc:0.8750\n",
      "Epoch: 19, Batch: 32000, Train NLL: 0.5541, Train Acc:0.8125\n",
      "Epoch: 19, Batch: 33000, Train NLL: 0.4515, Train Acc:0.8125\n",
      "Epoch: 19, Batch: 34000, Train NLL: 0.4023, Train Acc:0.9375\n",
      "Epoch: 19, Val NLL: 0.6278, Val Acc: 0.7374\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 20, Batch: 0, Train NLL: 0.7327, Train Acc:0.6250\n",
      "Epoch: 20, Batch: 1000, Train NLL: 0.6520, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 2000, Train NLL: 0.5941, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 3000, Train NLL: 0.5635, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 4000, Train NLL: 0.6397, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 5000, Train NLL: 0.6350, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 6000, Train NLL: 0.4884, Train Acc:0.8125\n",
      "Epoch: 20, Batch: 7000, Train NLL: 0.8892, Train Acc:0.5000\n",
      "Epoch: 20, Batch: 8000, Train NLL: 0.7024, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 9000, Train NLL: 0.6979, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 10000, Train NLL: 0.5577, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 11000, Train NLL: 0.6853, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 12000, Train NLL: 0.5742, Train Acc:0.6250\n",
      "Epoch: 20, Batch: 13000, Train NLL: 0.9549, Train Acc:0.4375\n",
      "Epoch: 20, Batch: 14000, Train NLL: 0.5111, Train Acc:0.8125\n",
      "Epoch: 20, Batch: 15000, Train NLL: 0.6657, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 16000, Train NLL: 1.0878, Train Acc:0.4375\n",
      "Epoch: 20, Batch: 17000, Train NLL: 0.4964, Train Acc:0.8750\n",
      "Epoch: 20, Batch: 18000, Train NLL: 0.6865, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 19000, Train NLL: 0.5488, Train Acc:0.8750\n",
      "Epoch: 20, Batch: 20000, Train NLL: 0.6307, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 21000, Train NLL: 0.8788, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 22000, Train NLL: 0.6260, Train Acc:0.6250\n",
      "Epoch: 20, Batch: 23000, Train NLL: 0.6590, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 24000, Train NLL: 0.4491, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 25000, Train NLL: 0.5728, Train Acc:0.8125\n",
      "Epoch: 20, Batch: 26000, Train NLL: 0.5297, Train Acc:0.8125\n",
      "Epoch: 20, Batch: 27000, Train NLL: 0.3070, Train Acc:0.9375\n",
      "Epoch: 20, Batch: 28000, Train NLL: 0.7746, Train Acc:0.6250\n",
      "Epoch: 20, Batch: 29000, Train NLL: 0.8110, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 30000, Train NLL: 0.5492, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 31000, Train NLL: 0.6312, Train Acc:0.6875\n",
      "Epoch: 20, Batch: 32000, Train NLL: 0.4961, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 33000, Train NLL: 0.4953, Train Acc:0.7500\n",
      "Epoch: 20, Batch: 34000, Train NLL: 0.4935, Train Acc:0.7500\n",
      "Epoch: 20, Val NLL: 0.6389, Val Acc: 0.7337\n",
      "LR = 0.025\n",
      "Epoch: 21, Batch: 0, Train NLL: 0.6711, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 1000, Train NLL: 0.3478, Train Acc:0.8125\n",
      "Epoch: 21, Batch: 2000, Train NLL: 0.6314, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 3000, Train NLL: 0.5586, Train Acc:0.8125\n",
      "Epoch: 21, Batch: 4000, Train NLL: 0.6219, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 5000, Train NLL: 0.8730, Train Acc:0.5625\n",
      "Epoch: 21, Batch: 6000, Train NLL: 0.4437, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 7000, Train NLL: 0.3087, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 8000, Train NLL: 0.6767, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 9000, Train NLL: 0.6691, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 10000, Train NLL: 0.4248, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 11000, Train NLL: 0.5989, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 12000, Train NLL: 0.3455, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 13000, Train NLL: 0.6687, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 14000, Train NLL: 0.7140, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 15000, Train NLL: 0.7066, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 16000, Train NLL: 0.4178, Train Acc:0.9375\n",
      "Epoch: 21, Batch: 17000, Train NLL: 0.3461, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 18000, Train NLL: 0.6417, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 19000, Train NLL: 0.5076, Train Acc:0.8125\n",
      "Epoch: 21, Batch: 20000, Train NLL: 0.4279, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 21000, Train NLL: 0.6350, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 22000, Train NLL: 0.9532, Train Acc:0.5000\n",
      "Epoch: 21, Batch: 23000, Train NLL: 0.8927, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 24000, Train NLL: 0.3703, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 25000, Train NLL: 0.6445, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 26000, Train NLL: 0.5855, Train Acc:0.7500\n",
      "Epoch: 21, Batch: 27000, Train NLL: 0.3343, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 28000, Train NLL: 1.0205, Train Acc:0.6875\n",
      "Epoch: 21, Batch: 29000, Train NLL: 0.6179, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 30000, Train NLL: 0.6638, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 31000, Train NLL: 0.7239, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 32000, Train NLL: 0.5380, Train Acc:0.8750\n",
      "Epoch: 21, Batch: 33000, Train NLL: 0.6345, Train Acc:0.6250\n",
      "Epoch: 21, Batch: 34000, Train NLL: 0.8039, Train Acc:0.6250\n",
      "Epoch: 21, Val NLL: 0.6255, Val Acc: 0.7384\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 22, Batch: 0, Train NLL: 0.7282, Train Acc:0.6875\n",
      "Epoch: 22, Batch: 1000, Train NLL: 0.7585, Train Acc:0.6875\n",
      "Epoch: 22, Batch: 2000, Train NLL: 0.3586, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 3000, Train NLL: 0.7285, Train Acc:0.5625\n",
      "Epoch: 22, Batch: 4000, Train NLL: 0.5173, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 5000, Train NLL: 0.4084, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 6000, Train NLL: 0.7790, Train Acc:0.6875\n",
      "Epoch: 22, Batch: 7000, Train NLL: 0.4469, Train Acc:0.8750\n",
      "Epoch: 22, Batch: 8000, Train NLL: 0.4202, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 9000, Train NLL: 0.5727, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 10000, Train NLL: 1.1419, Train Acc:0.4375\n",
      "Epoch: 22, Batch: 11000, Train NLL: 0.6177, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 12000, Train NLL: 0.5983, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 13000, Train NLL: 0.4428, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 14000, Train NLL: 0.4458, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 15000, Train NLL: 0.6225, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 16000, Train NLL: 0.6956, Train Acc:0.6250\n",
      "Epoch: 22, Batch: 17000, Train NLL: 0.3486, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 18000, Train NLL: 0.5117, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 19000, Train NLL: 0.5317, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 20000, Train NLL: 0.5662, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 21000, Train NLL: 0.5778, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 22000, Train NLL: 0.3340, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 23000, Train NLL: 0.7232, Train Acc:0.6875\n",
      "Epoch: 22, Batch: 24000, Train NLL: 0.3807, Train Acc:0.8750\n",
      "Epoch: 22, Batch: 25000, Train NLL: 0.9238, Train Acc:0.6250\n",
      "Epoch: 22, Batch: 26000, Train NLL: 0.5895, Train Acc:0.8125\n",
      "Epoch: 22, Batch: 27000, Train NLL: 0.6042, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 28000, Train NLL: 0.4070, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 29000, Train NLL: 0.9962, Train Acc:0.6250\n",
      "Epoch: 22, Batch: 30000, Train NLL: 0.8044, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 31000, Train NLL: 0.7194, Train Acc:0.6875\n",
      "Epoch: 22, Batch: 32000, Train NLL: 0.8113, Train Acc:0.7500\n",
      "Epoch: 22, Batch: 33000, Train NLL: 0.2976, Train Acc:0.9375\n",
      "Epoch: 22, Batch: 34000, Train NLL: 0.5979, Train Acc:0.7500\n",
      "Epoch: 22, Val NLL: 0.6206, Val Acc: 0.7408\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 23, Batch: 0, Train NLL: 0.2997, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 1000, Train NLL: 0.5095, Train Acc:0.8125\n",
      "Epoch: 23, Batch: 2000, Train NLL: 0.5825, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 3000, Train NLL: 0.7557, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 4000, Train NLL: 0.7172, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 5000, Train NLL: 0.4933, Train Acc:0.8125\n",
      "Epoch: 23, Batch: 6000, Train NLL: 0.3257, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 7000, Train NLL: 0.5061, Train Acc:0.7500\n",
      "Epoch: 23, Batch: 8000, Train NLL: 0.6251, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 9000, Train NLL: 0.8785, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 10000, Train NLL: 0.9039, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 11000, Train NLL: 0.5621, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 12000, Train NLL: 0.4888, Train Acc:0.8125\n",
      "Epoch: 23, Batch: 13000, Train NLL: 0.7293, Train Acc:0.5625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, Batch: 14000, Train NLL: 0.8116, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 15000, Train NLL: 0.4118, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 16000, Train NLL: 0.7189, Train Acc:0.7500\n",
      "Epoch: 23, Batch: 17000, Train NLL: 0.6969, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 18000, Train NLL: 0.9099, Train Acc:0.5625\n",
      "Epoch: 23, Batch: 19000, Train NLL: 0.3078, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 20000, Train NLL: 0.6288, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 21000, Train NLL: 0.7661, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 22000, Train NLL: 0.8289, Train Acc:0.5625\n",
      "Epoch: 23, Batch: 23000, Train NLL: 0.7883, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 24000, Train NLL: 0.5754, Train Acc:0.8125\n",
      "Epoch: 23, Batch: 25000, Train NLL: 0.4289, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 26000, Train NLL: 0.5018, Train Acc:0.7500\n",
      "Epoch: 23, Batch: 27000, Train NLL: 0.4411, Train Acc:0.9375\n",
      "Epoch: 23, Batch: 28000, Train NLL: 0.7542, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 29000, Train NLL: 0.4606, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 30000, Train NLL: 0.7009, Train Acc:0.6250\n",
      "Epoch: 23, Batch: 31000, Train NLL: 0.5130, Train Acc:0.8125\n",
      "Epoch: 23, Batch: 32000, Train NLL: 0.6747, Train Acc:0.6875\n",
      "Epoch: 23, Batch: 33000, Train NLL: 0.4132, Train Acc:0.8750\n",
      "Epoch: 23, Batch: 34000, Train NLL: 0.3716, Train Acc:0.8750\n",
      "Epoch: 23, Val NLL: 0.6225, Val Acc: 0.7405\n",
      "LR = 0.025\n",
      "Epoch: 24, Batch: 0, Train NLL: 0.5884, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 1000, Train NLL: 0.7937, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 2000, Train NLL: 0.4596, Train Acc:0.8750\n",
      "Epoch: 24, Batch: 3000, Train NLL: 0.5288, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 4000, Train NLL: 0.5753, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 5000, Train NLL: 0.6957, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 6000, Train NLL: 0.5065, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 7000, Train NLL: 0.5829, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 8000, Train NLL: 0.8780, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 9000, Train NLL: 0.6076, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 10000, Train NLL: 0.4065, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 11000, Train NLL: 0.5842, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 12000, Train NLL: 0.7197, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 13000, Train NLL: 0.5235, Train Acc:0.6250\n",
      "Epoch: 24, Batch: 14000, Train NLL: 0.4851, Train Acc:0.8750\n",
      "Epoch: 24, Batch: 15000, Train NLL: 0.8294, Train Acc:0.6250\n",
      "Epoch: 24, Batch: 16000, Train NLL: 0.6407, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 17000, Train NLL: 0.3423, Train Acc:0.9375\n",
      "Epoch: 24, Batch: 18000, Train NLL: 0.8938, Train Acc:0.5000\n",
      "Epoch: 24, Batch: 19000, Train NLL: 0.6304, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 20000, Train NLL: 0.5042, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 21000, Train NLL: 0.5511, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 22000, Train NLL: 0.3835, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 23000, Train NLL: 0.4027, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 24000, Train NLL: 0.7671, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 25000, Train NLL: 0.5674, Train Acc:0.8750\n",
      "Epoch: 24, Batch: 26000, Train NLL: 0.7779, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 27000, Train NLL: 0.4296, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 28000, Train NLL: 0.6348, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 29000, Train NLL: 0.7399, Train Acc:0.6250\n",
      "Epoch: 24, Batch: 30000, Train NLL: 0.6642, Train Acc:0.7500\n",
      "Epoch: 24, Batch: 31000, Train NLL: 0.6222, Train Acc:0.8125\n",
      "Epoch: 24, Batch: 32000, Train NLL: 0.7227, Train Acc:0.6250\n",
      "Epoch: 24, Batch: 33000, Train NLL: 0.6173, Train Acc:0.6875\n",
      "Epoch: 24, Batch: 34000, Train NLL: 0.3101, Train Acc:0.9375\n",
      "Epoch: 24, Val NLL: 0.6177, Val Acc: 0.7443\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 25, Batch: 0, Train NLL: 0.6932, Train Acc:0.6250\n",
      "Epoch: 25, Batch: 1000, Train NLL: 0.6832, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 2000, Train NLL: 0.9808, Train Acc:0.6250\n",
      "Epoch: 25, Batch: 3000, Train NLL: 0.3420, Train Acc:0.9375\n",
      "Epoch: 25, Batch: 4000, Train NLL: 0.4644, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 5000, Train NLL: 0.5769, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 6000, Train NLL: 0.2627, Train Acc:0.9375\n",
      "Epoch: 25, Batch: 7000, Train NLL: 0.6588, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 8000, Train NLL: 0.7628, Train Acc:0.5625\n",
      "Epoch: 25, Batch: 9000, Train NLL: 0.5194, Train Acc:0.7500\n",
      "Epoch: 25, Batch: 10000, Train NLL: 0.9000, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 11000, Train NLL: 0.4276, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 12000, Train NLL: 0.7761, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 13000, Train NLL: 0.7594, Train Acc:0.5625\n",
      "Epoch: 25, Batch: 14000, Train NLL: 0.6106, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 15000, Train NLL: 0.3386, Train Acc:0.8750\n",
      "Epoch: 25, Batch: 16000, Train NLL: 0.4730, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 17000, Train NLL: 0.9062, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 18000, Train NLL: 0.9885, Train Acc:0.5625\n",
      "Epoch: 25, Batch: 19000, Train NLL: 0.7612, Train Acc:0.6250\n",
      "Epoch: 25, Batch: 20000, Train NLL: 0.6195, Train Acc:0.7500\n",
      "Epoch: 25, Batch: 21000, Train NLL: 0.4853, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 22000, Train NLL: 0.4493, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 23000, Train NLL: 0.2898, Train Acc:0.8750\n",
      "Epoch: 25, Batch: 24000, Train NLL: 0.5775, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 25000, Train NLL: 0.8524, Train Acc:0.6250\n",
      "Epoch: 25, Batch: 26000, Train NLL: 0.5361, Train Acc:0.8125\n",
      "Epoch: 25, Batch: 27000, Train NLL: 0.3232, Train Acc:0.8750\n",
      "Epoch: 25, Batch: 28000, Train NLL: 0.9783, Train Acc:0.5625\n",
      "Epoch: 25, Batch: 29000, Train NLL: 0.7041, Train Acc:0.6250\n",
      "Epoch: 25, Batch: 30000, Train NLL: 0.6463, Train Acc:0.7500\n",
      "Epoch: 25, Batch: 31000, Train NLL: 0.5741, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 32000, Train NLL: 0.4548, Train Acc:0.6875\n",
      "Epoch: 25, Batch: 33000, Train NLL: 0.2665, Train Acc:0.9375\n",
      "Epoch: 25, Batch: 34000, Train NLL: 0.5299, Train Acc:0.7500\n",
      "Epoch: 25, Val NLL: 0.6141, Val Acc: 0.7442\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 26, Batch: 0, Train NLL: 0.6449, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 1000, Train NLL: 0.4447, Train Acc:0.9375\n",
      "Epoch: 26, Batch: 2000, Train NLL: 0.7792, Train Acc:0.6250\n",
      "Epoch: 26, Batch: 3000, Train NLL: 0.4596, Train Acc:0.8750\n",
      "Epoch: 26, Batch: 4000, Train NLL: 0.8675, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 5000, Train NLL: 0.6833, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 6000, Train NLL: 0.7542, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 7000, Train NLL: 0.7039, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 8000, Train NLL: 0.5619, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 9000, Train NLL: 0.4428, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 10000, Train NLL: 0.5215, Train Acc:0.8750\n",
      "Epoch: 26, Batch: 11000, Train NLL: 0.3684, Train Acc:0.8750\n",
      "Epoch: 26, Batch: 12000, Train NLL: 0.9332, Train Acc:0.5625\n",
      "Epoch: 26, Batch: 13000, Train NLL: 0.6364, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 14000, Train NLL: 0.5347, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 15000, Train NLL: 0.5654, Train Acc:0.6250\n",
      "Epoch: 26, Batch: 16000, Train NLL: 0.3224, Train Acc:0.9375\n",
      "Epoch: 26, Batch: 17000, Train NLL: 0.7386, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 18000, Train NLL: 0.5551, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 19000, Train NLL: 0.8435, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 20000, Train NLL: 0.4201, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 21000, Train NLL: 0.5317, Train Acc:0.8750\n",
      "Epoch: 26, Batch: 22000, Train NLL: 0.5840, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 23000, Train NLL: 0.5902, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 24000, Train NLL: 0.7823, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 25000, Train NLL: 0.6787, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 26000, Train NLL: 0.7384, Train Acc:0.5625\n",
      "Epoch: 26, Batch: 27000, Train NLL: 0.7034, Train Acc:0.7500\n",
      "Epoch: 26, Batch: 28000, Train NLL: 0.5000, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 29000, Train NLL: 0.7948, Train Acc:0.6875\n",
      "Epoch: 26, Batch: 30000, Train NLL: 0.7168, Train Acc:0.6250\n",
      "Epoch: 26, Batch: 31000, Train NLL: 0.5715, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 32000, Train NLL: 0.5876, Train Acc:0.8125\n",
      "Epoch: 26, Batch: 33000, Train NLL: 0.7718, Train Acc:0.6250\n",
      "Epoch: 26, Batch: 34000, Train NLL: 0.6555, Train Acc:0.7500\n",
      "Epoch: 26, Val NLL: 0.6127, Val Acc: 0.7462\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 27, Batch: 0, Train NLL: 0.4601, Train Acc:0.8750\n",
      "Epoch: 27, Batch: 1000, Train NLL: 0.4568, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 2000, Train NLL: 0.7651, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 3000, Train NLL: 0.9115, Train Acc:0.6250\n",
      "Epoch: 27, Batch: 4000, Train NLL: 0.7077, Train Acc:0.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, Batch: 5000, Train NLL: 0.8396, Train Acc:0.7500\n",
      "Epoch: 27, Batch: 6000, Train NLL: 0.7883, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 7000, Train NLL: 0.4496, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 8000, Train NLL: 0.4594, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 9000, Train NLL: 0.4099, Train Acc:0.8750\n",
      "Epoch: 27, Batch: 10000, Train NLL: 0.4368, Train Acc:0.8750\n",
      "Epoch: 27, Batch: 11000, Train NLL: 0.6231, Train Acc:0.6250\n",
      "Epoch: 27, Batch: 12000, Train NLL: 0.4981, Train Acc:0.8750\n",
      "Epoch: 27, Batch: 13000, Train NLL: 0.5261, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 14000, Train NLL: 0.7683, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 15000, Train NLL: 0.6209, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 16000, Train NLL: 0.7906, Train Acc:0.7500\n",
      "Epoch: 27, Batch: 17000, Train NLL: 0.5276, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 18000, Train NLL: 0.6693, Train Acc:0.7500\n",
      "Epoch: 27, Batch: 19000, Train NLL: 0.7052, Train Acc:0.7500\n",
      "Epoch: 27, Batch: 20000, Train NLL: 0.6671, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 21000, Train NLL: 0.6303, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 22000, Train NLL: 0.3942, Train Acc:0.9375\n",
      "Epoch: 27, Batch: 23000, Train NLL: 0.3276, Train Acc:0.9375\n",
      "Epoch: 27, Batch: 24000, Train NLL: 0.5372, Train Acc:0.7500\n",
      "Epoch: 27, Batch: 25000, Train NLL: 0.5389, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 26000, Train NLL: 0.3825, Train Acc:0.9375\n",
      "Epoch: 27, Batch: 27000, Train NLL: 0.7749, Train Acc:0.6250\n",
      "Epoch: 27, Batch: 28000, Train NLL: 0.4538, Train Acc:0.8750\n",
      "Epoch: 27, Batch: 29000, Train NLL: 0.8479, Train Acc:0.6250\n",
      "Epoch: 27, Batch: 30000, Train NLL: 0.7560, Train Acc:0.6250\n",
      "Epoch: 27, Batch: 31000, Train NLL: 0.9092, Train Acc:0.4375\n",
      "Epoch: 27, Batch: 32000, Train NLL: 0.6625, Train Acc:0.6875\n",
      "Epoch: 27, Batch: 33000, Train NLL: 0.4289, Train Acc:0.8125\n",
      "Epoch: 27, Batch: 34000, Train NLL: 0.3560, Train Acc:0.9375\n",
      "Epoch: 27, Val NLL: 0.6130, Val Acc: 0.7473\n",
      "LR = 0.025\n",
      "Epoch: 28, Batch: 0, Train NLL: 0.7111, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 1000, Train NLL: 0.6240, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 2000, Train NLL: 0.3095, Train Acc:0.9375\n",
      "Epoch: 28, Batch: 3000, Train NLL: 0.6508, Train Acc:0.6875\n",
      "Epoch: 28, Batch: 4000, Train NLL: 0.6694, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 5000, Train NLL: 0.7079, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 6000, Train NLL: 0.6117, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 7000, Train NLL: 0.5701, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 8000, Train NLL: 0.3066, Train Acc:1.0000\n",
      "Epoch: 28, Batch: 9000, Train NLL: 0.4124, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 10000, Train NLL: 0.4650, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 11000, Train NLL: 0.6366, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 12000, Train NLL: 0.7056, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 13000, Train NLL: 0.8900, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 14000, Train NLL: 0.4952, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 15000, Train NLL: 0.5344, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 16000, Train NLL: 0.6947, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 17000, Train NLL: 0.4064, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 18000, Train NLL: 0.6704, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 19000, Train NLL: 0.3905, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 20000, Train NLL: 0.5055, Train Acc:0.8125\n",
      "Epoch: 28, Batch: 21000, Train NLL: 0.5818, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 22000, Train NLL: 0.5136, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 23000, Train NLL: 0.6816, Train Acc:0.6875\n",
      "Epoch: 28, Batch: 24000, Train NLL: 0.6812, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 25000, Train NLL: 0.2430, Train Acc:0.9375\n",
      "Epoch: 28, Batch: 26000, Train NLL: 0.9954, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 27000, Train NLL: 0.8591, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 28000, Train NLL: 0.4569, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 29000, Train NLL: 0.5615, Train Acc:0.7500\n",
      "Epoch: 28, Batch: 30000, Train NLL: 0.8691, Train Acc:0.6250\n",
      "Epoch: 28, Batch: 31000, Train NLL: 0.3577, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 32000, Train NLL: 0.4118, Train Acc:0.8750\n",
      "Epoch: 28, Batch: 33000, Train NLL: 0.8181, Train Acc:0.6875\n",
      "Epoch: 28, Batch: 34000, Train NLL: 0.6527, Train Acc:0.6875\n",
      "Epoch: 28, Val NLL: 0.6134, Val Acc: 0.7455\n",
      "LR = 0.025\n",
      "Epoch: 29, Batch: 0, Train NLL: 0.5544, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 1000, Train NLL: 0.5593, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 2000, Train NLL: 0.6880, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 3000, Train NLL: 0.7296, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 4000, Train NLL: 0.7123, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 5000, Train NLL: 0.6048, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 6000, Train NLL: 0.2563, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 7000, Train NLL: 0.3265, Train Acc:0.8750\n",
      "Epoch: 29, Batch: 8000, Train NLL: 0.6720, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 9000, Train NLL: 0.3985, Train Acc:0.8750\n",
      "Epoch: 29, Batch: 10000, Train NLL: 0.4019, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 11000, Train NLL: 0.4542, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 12000, Train NLL: 0.5613, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 13000, Train NLL: 0.6080, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 14000, Train NLL: 0.4443, Train Acc:0.8750\n",
      "Epoch: 29, Batch: 15000, Train NLL: 0.3018, Train Acc:0.9375\n",
      "Epoch: 29, Batch: 16000, Train NLL: 0.5019, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 17000, Train NLL: 0.6621, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 18000, Train NLL: 0.7678, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 19000, Train NLL: 0.6794, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 20000, Train NLL: 0.3334, Train Acc:0.8750\n",
      "Epoch: 29, Batch: 21000, Train NLL: 0.5747, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 22000, Train NLL: 0.6174, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 23000, Train NLL: 0.8556, Train Acc:0.5625\n",
      "Epoch: 29, Batch: 24000, Train NLL: 0.8168, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 25000, Train NLL: 0.3145, Train Acc:0.8750\n",
      "Epoch: 29, Batch: 26000, Train NLL: 0.7156, Train Acc:0.6250\n",
      "Epoch: 29, Batch: 27000, Train NLL: 0.4449, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 28000, Train NLL: 0.6074, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 29000, Train NLL: 0.7197, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 30000, Train NLL: 0.7297, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 31000, Train NLL: 0.9407, Train Acc:0.7500\n",
      "Epoch: 29, Batch: 32000, Train NLL: 0.5345, Train Acc:0.6875\n",
      "Epoch: 29, Batch: 33000, Train NLL: 0.4788, Train Acc:0.8125\n",
      "Epoch: 29, Batch: 34000, Train NLL: 0.6905, Train Acc:0.6250\n",
      "Epoch: 29, Val NLL: 0.6130, Val Acc: 0.7458\n",
      "LR = 0.025\n",
      "Epoch: 30, Batch: 0, Train NLL: 0.6401, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 1000, Train NLL: 0.6580, Train Acc:0.6875\n",
      "Epoch: 30, Batch: 2000, Train NLL: 0.4687, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 3000, Train NLL: 0.4143, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 4000, Train NLL: 0.7170, Train Acc:0.6250\n",
      "Epoch: 30, Batch: 5000, Train NLL: 0.3155, Train Acc:0.9375\n",
      "Epoch: 30, Batch: 6000, Train NLL: 0.7146, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 7000, Train NLL: 0.6954, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 8000, Train NLL: 0.5919, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 9000, Train NLL: 0.4765, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 10000, Train NLL: 0.3483, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 11000, Train NLL: 0.5531, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 12000, Train NLL: 0.8501, Train Acc:0.5625\n",
      "Epoch: 30, Batch: 13000, Train NLL: 0.6541, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 14000, Train NLL: 0.4781, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 15000, Train NLL: 0.7787, Train Acc:0.5625\n",
      "Epoch: 30, Batch: 16000, Train NLL: 0.5313, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 17000, Train NLL: 0.6177, Train Acc:0.6875\n",
      "Epoch: 30, Batch: 18000, Train NLL: 0.2727, Train Acc:0.9375\n",
      "Epoch: 30, Batch: 19000, Train NLL: 0.7297, Train Acc:0.6875\n",
      "Epoch: 30, Batch: 20000, Train NLL: 0.8038, Train Acc:0.6875\n",
      "Epoch: 30, Batch: 21000, Train NLL: 0.5939, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 22000, Train NLL: 0.7795, Train Acc:0.6250\n",
      "Epoch: 30, Batch: 23000, Train NLL: 0.7339, Train Acc:0.6875\n",
      "Epoch: 30, Batch: 24000, Train NLL: 0.3862, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 25000, Train NLL: 0.3967, Train Acc:0.8750\n",
      "Epoch: 30, Batch: 26000, Train NLL: 0.7185, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 27000, Train NLL: 0.3874, Train Acc:0.9375\n",
      "Epoch: 30, Batch: 28000, Train NLL: 0.5996, Train Acc:0.7500\n",
      "Epoch: 30, Batch: 29000, Train NLL: 0.4959, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 30000, Train NLL: 0.5528, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 31000, Train NLL: 0.9185, Train Acc:0.5625\n",
      "Epoch: 30, Batch: 32000, Train NLL: 0.3983, Train Acc:0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30, Batch: 33000, Train NLL: 0.4444, Train Acc:0.8125\n",
      "Epoch: 30, Batch: 34000, Train NLL: 0.7760, Train Acc:0.6250\n",
      "Epoch: 30, Val NLL: 0.6119, Val Acc: 0.7463\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 31, Batch: 0, Train NLL: 0.2546, Train Acc:0.9375\n",
      "Epoch: 31, Batch: 1000, Train NLL: 0.4059, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 2000, Train NLL: 0.3599, Train Acc:0.8750\n",
      "Epoch: 31, Batch: 3000, Train NLL: 0.5894, Train Acc:0.6250\n",
      "Epoch: 31, Batch: 4000, Train NLL: 0.5441, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 5000, Train NLL: 1.0278, Train Acc:0.5625\n",
      "Epoch: 31, Batch: 6000, Train NLL: 0.3512, Train Acc:0.9375\n",
      "Epoch: 31, Batch: 7000, Train NLL: 0.4621, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 8000, Train NLL: 0.5124, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 9000, Train NLL: 0.5855, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 10000, Train NLL: 0.5418, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 11000, Train NLL: 0.7057, Train Acc:0.6250\n",
      "Epoch: 31, Batch: 12000, Train NLL: 0.6028, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 13000, Train NLL: 0.5214, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 14000, Train NLL: 0.5478, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 15000, Train NLL: 0.5780, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 16000, Train NLL: 0.5416, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 17000, Train NLL: 0.7938, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 18000, Train NLL: 0.4557, Train Acc:0.9375\n",
      "Epoch: 31, Batch: 19000, Train NLL: 0.6035, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 20000, Train NLL: 0.5783, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 21000, Train NLL: 0.3531, Train Acc:0.8750\n",
      "Epoch: 31, Batch: 22000, Train NLL: 0.5399, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 23000, Train NLL: 0.6533, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 24000, Train NLL: 0.5708, Train Acc:0.6875\n",
      "Epoch: 31, Batch: 25000, Train NLL: 0.8491, Train Acc:0.5000\n",
      "Epoch: 31, Batch: 26000, Train NLL: 0.4251, Train Acc:0.8750\n",
      "Epoch: 31, Batch: 27000, Train NLL: 0.4765, Train Acc:0.8750\n",
      "Epoch: 31, Batch: 28000, Train NLL: 0.7137, Train Acc:0.6250\n",
      "Epoch: 31, Batch: 29000, Train NLL: 0.5797, Train Acc:0.8125\n",
      "Epoch: 31, Batch: 30000, Train NLL: 0.5375, Train Acc:0.8750\n",
      "Epoch: 31, Batch: 31000, Train NLL: 0.4824, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 32000, Train NLL: 0.7331, Train Acc:0.7500\n",
      "Epoch: 31, Batch: 33000, Train NLL: 1.1791, Train Acc:0.4375\n",
      "Epoch: 31, Batch: 34000, Train NLL: 0.5349, Train Acc:0.8125\n",
      "Epoch: 31, Val NLL: 0.6072, Val Acc: 0.7484\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 32, Batch: 0, Train NLL: 0.6485, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 1000, Train NLL: 0.6783, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 2000, Train NLL: 0.6395, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 3000, Train NLL: 0.8106, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 4000, Train NLL: 0.8067, Train Acc:0.5625\n",
      "Epoch: 32, Batch: 5000, Train NLL: 0.7730, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 6000, Train NLL: 0.6641, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 7000, Train NLL: 0.4876, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 8000, Train NLL: 0.7780, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 9000, Train NLL: 0.8433, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 10000, Train NLL: 0.5180, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 11000, Train NLL: 0.6573, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 12000, Train NLL: 0.6853, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 13000, Train NLL: 0.8162, Train Acc:0.5625\n",
      "Epoch: 32, Batch: 14000, Train NLL: 0.6288, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 15000, Train NLL: 0.4841, Train Acc:0.8750\n",
      "Epoch: 32, Batch: 16000, Train NLL: 0.3813, Train Acc:0.8125\n",
      "Epoch: 32, Batch: 17000, Train NLL: 0.6143, Train Acc:0.8125\n",
      "Epoch: 32, Batch: 18000, Train NLL: 0.3938, Train Acc:0.8750\n",
      "Epoch: 32, Batch: 19000, Train NLL: 0.4738, Train Acc:0.8125\n",
      "Epoch: 32, Batch: 20000, Train NLL: 0.6255, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 21000, Train NLL: 0.2949, Train Acc:0.9375\n",
      "Epoch: 32, Batch: 22000, Train NLL: 0.6329, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 23000, Train NLL: 0.5860, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 24000, Train NLL: 0.4942, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 25000, Train NLL: 0.8682, Train Acc:0.5625\n",
      "Epoch: 32, Batch: 26000, Train NLL: 0.4875, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 27000, Train NLL: 0.4352, Train Acc:0.8750\n",
      "Epoch: 32, Batch: 28000, Train NLL: 0.6653, Train Acc:0.6875\n",
      "Epoch: 32, Batch: 29000, Train NLL: 0.8487, Train Acc:0.6250\n",
      "Epoch: 32, Batch: 30000, Train NLL: 0.5397, Train Acc:0.7500\n",
      "Epoch: 32, Batch: 31000, Train NLL: 0.5363, Train Acc:0.8750\n",
      "Epoch: 32, Batch: 32000, Train NLL: 0.2475, Train Acc:1.0000\n",
      "Epoch: 32, Batch: 33000, Train NLL: 0.4451, Train Acc:0.8750\n",
      "Epoch: 32, Batch: 34000, Train NLL: 0.3976, Train Acc:0.8125\n",
      "Epoch: 32, Val NLL: 0.6132, Val Acc: 0.7439\n",
      "LR = 0.025\n",
      "Epoch: 33, Batch: 0, Train NLL: 0.5532, Train Acc:0.8750\n",
      "Epoch: 33, Batch: 1000, Train NLL: 0.5863, Train Acc:0.6875\n",
      "Epoch: 33, Batch: 2000, Train NLL: 0.4195, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 3000, Train NLL: 0.4174, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 4000, Train NLL: 0.4750, Train Acc:0.8750\n",
      "Epoch: 33, Batch: 5000, Train NLL: 0.4205, Train Acc:0.8750\n",
      "Epoch: 33, Batch: 6000, Train NLL: 0.7150, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 7000, Train NLL: 0.5708, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 8000, Train NLL: 0.6231, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 9000, Train NLL: 0.5912, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 10000, Train NLL: 0.7901, Train Acc:0.5625\n",
      "Epoch: 33, Batch: 11000, Train NLL: 0.6224, Train Acc:0.6250\n",
      "Epoch: 33, Batch: 12000, Train NLL: 0.7275, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 13000, Train NLL: 0.4653, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 14000, Train NLL: 0.7310, Train Acc:0.6875\n",
      "Epoch: 33, Batch: 15000, Train NLL: 0.4402, Train Acc:0.9375\n",
      "Epoch: 33, Batch: 16000, Train NLL: 0.4069, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 17000, Train NLL: 0.5716, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 18000, Train NLL: 0.6550, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 19000, Train NLL: 0.5012, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 20000, Train NLL: 0.8446, Train Acc:0.5625\n",
      "Epoch: 33, Batch: 21000, Train NLL: 0.7938, Train Acc:0.6875\n",
      "Epoch: 33, Batch: 22000, Train NLL: 0.7653, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 23000, Train NLL: 0.7875, Train Acc:0.6250\n",
      "Epoch: 33, Batch: 24000, Train NLL: 0.3845, Train Acc:0.8750\n",
      "Epoch: 33, Batch: 25000, Train NLL: 0.4217, Train Acc:0.8125\n",
      "Epoch: 33, Batch: 26000, Train NLL: 0.5044, Train Acc:0.8750\n",
      "Epoch: 33, Batch: 27000, Train NLL: 0.4387, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 28000, Train NLL: 0.6475, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 29000, Train NLL: 0.7320, Train Acc:0.6250\n",
      "Epoch: 33, Batch: 30000, Train NLL: 0.8953, Train Acc:0.6250\n",
      "Epoch: 33, Batch: 31000, Train NLL: 0.7192, Train Acc:0.6875\n",
      "Epoch: 33, Batch: 32000, Train NLL: 0.5751, Train Acc:0.6875\n",
      "Epoch: 33, Batch: 33000, Train NLL: 0.5862, Train Acc:0.7500\n",
      "Epoch: 33, Batch: 34000, Train NLL: 0.6119, Train Acc:0.6875\n",
      "Epoch: 33, Val NLL: 0.6054, Val Acc: 0.7504\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 34, Batch: 0, Train NLL: 0.5486, Train Acc:0.8125\n",
      "Epoch: 34, Batch: 1000, Train NLL: 0.3437, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 2000, Train NLL: 0.5143, Train Acc:0.8125\n",
      "Epoch: 34, Batch: 3000, Train NLL: 0.4265, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 4000, Train NLL: 0.6543, Train Acc:0.6250\n",
      "Epoch: 34, Batch: 5000, Train NLL: 0.8484, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 6000, Train NLL: 0.8647, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 7000, Train NLL: 0.6874, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 8000, Train NLL: 0.6095, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 9000, Train NLL: 0.4460, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 10000, Train NLL: 0.5458, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 11000, Train NLL: 0.7895, Train Acc:0.6250\n",
      "Epoch: 34, Batch: 12000, Train NLL: 0.5154, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 13000, Train NLL: 0.6690, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 14000, Train NLL: 0.6186, Train Acc:0.8125\n",
      "Epoch: 34, Batch: 15000, Train NLL: 0.6855, Train Acc:0.6250\n",
      "Epoch: 34, Batch: 16000, Train NLL: 0.6975, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 17000, Train NLL: 0.3883, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 18000, Train NLL: 0.7913, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 19000, Train NLL: 0.2200, Train Acc:0.9375\n",
      "Epoch: 34, Batch: 20000, Train NLL: 0.5368, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 21000, Train NLL: 0.4008, Train Acc:0.8125\n",
      "Epoch: 34, Batch: 22000, Train NLL: 1.2818, Train Acc:0.5000\n",
      "Epoch: 34, Batch: 23000, Train NLL: 0.5359, Train Acc:0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34, Batch: 24000, Train NLL: 0.4179, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 25000, Train NLL: 0.5570, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 26000, Train NLL: 0.4032, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 27000, Train NLL: 0.4390, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 28000, Train NLL: 1.1542, Train Acc:0.3750\n",
      "Epoch: 34, Batch: 29000, Train NLL: 0.4051, Train Acc:0.8125\n",
      "Epoch: 34, Batch: 30000, Train NLL: 0.5627, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 31000, Train NLL: 0.7093, Train Acc:0.7500\n",
      "Epoch: 34, Batch: 32000, Train NLL: 0.3965, Train Acc:0.8750\n",
      "Epoch: 34, Batch: 33000, Train NLL: 0.7599, Train Acc:0.6875\n",
      "Epoch: 34, Batch: 34000, Train NLL: 0.8244, Train Acc:0.5625\n",
      "Epoch: 34, Val NLL: 0.6036, Val Acc: 0.7540\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 35, Batch: 0, Train NLL: 0.5061, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 1000, Train NLL: 0.4188, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 2000, Train NLL: 0.6337, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 3000, Train NLL: 0.2854, Train Acc:0.9375\n",
      "Epoch: 35, Batch: 4000, Train NLL: 0.7098, Train Acc:0.6250\n",
      "Epoch: 35, Batch: 5000, Train NLL: 0.5664, Train Acc:0.6250\n",
      "Epoch: 35, Batch: 6000, Train NLL: 0.6572, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 7000, Train NLL: 0.4488, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 8000, Train NLL: 0.5796, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 9000, Train NLL: 0.3751, Train Acc:0.8750\n",
      "Epoch: 35, Batch: 10000, Train NLL: 0.9737, Train Acc:0.5000\n",
      "Epoch: 35, Batch: 11000, Train NLL: 0.3549, Train Acc:0.8750\n",
      "Epoch: 35, Batch: 12000, Train NLL: 0.6188, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 13000, Train NLL: 0.6502, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 14000, Train NLL: 0.8225, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 15000, Train NLL: 0.2698, Train Acc:0.9375\n",
      "Epoch: 35, Batch: 16000, Train NLL: 0.6710, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 17000, Train NLL: 0.6103, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 18000, Train NLL: 0.5748, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 19000, Train NLL: 0.5322, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 20000, Train NLL: 0.7147, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 21000, Train NLL: 0.6226, Train Acc:0.6250\n",
      "Epoch: 35, Batch: 22000, Train NLL: 0.7090, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 23000, Train NLL: 0.8107, Train Acc:0.5625\n",
      "Epoch: 35, Batch: 24000, Train NLL: 0.4762, Train Acc:0.8750\n",
      "Epoch: 35, Batch: 25000, Train NLL: 0.5809, Train Acc:0.8125\n",
      "Epoch: 35, Batch: 26000, Train NLL: 0.6106, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 27000, Train NLL: 0.3800, Train Acc:0.8750\n",
      "Epoch: 35, Batch: 28000, Train NLL: 0.6433, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 29000, Train NLL: 0.5157, Train Acc:0.6875\n",
      "Epoch: 35, Batch: 30000, Train NLL: 0.9271, Train Acc:0.6250\n",
      "Epoch: 35, Batch: 31000, Train NLL: 0.4039, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 32000, Train NLL: 0.4291, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 33000, Train NLL: 0.5329, Train Acc:0.7500\n",
      "Epoch: 35, Batch: 34000, Train NLL: 0.5360, Train Acc:0.8125\n",
      "Epoch: 35, Val NLL: 0.6101, Val Acc: 0.7488\n",
      "LR = 0.025\n",
      "Epoch: 36, Batch: 0, Train NLL: 0.3442, Train Acc:0.8750\n",
      "Epoch: 36, Batch: 1000, Train NLL: 0.4493, Train Acc:0.8125\n",
      "Epoch: 36, Batch: 2000, Train NLL: 0.2789, Train Acc:0.8750\n",
      "Epoch: 36, Batch: 3000, Train NLL: 0.3899, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 4000, Train NLL: 0.2201, Train Acc:0.9375\n",
      "Epoch: 36, Batch: 5000, Train NLL: 0.5306, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 6000, Train NLL: 0.6851, Train Acc:0.6875\n",
      "Epoch: 36, Batch: 7000, Train NLL: 0.8044, Train Acc:0.5625\n",
      "Epoch: 36, Batch: 8000, Train NLL: 0.6624, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 9000, Train NLL: 0.7518, Train Acc:0.8125\n",
      "Epoch: 36, Batch: 10000, Train NLL: 0.6032, Train Acc:0.6875\n",
      "Epoch: 36, Batch: 11000, Train NLL: 0.7630, Train Acc:0.6250\n",
      "Epoch: 36, Batch: 12000, Train NLL: 0.7979, Train Acc:0.5625\n",
      "Epoch: 36, Batch: 13000, Train NLL: 0.6390, Train Acc:0.8125\n",
      "Epoch: 36, Batch: 14000, Train NLL: 0.5815, Train Acc:0.6875\n",
      "Epoch: 36, Batch: 15000, Train NLL: 0.3762, Train Acc:0.9375\n",
      "Epoch: 36, Batch: 16000, Train NLL: 0.5680, Train Acc:0.6250\n",
      "Epoch: 36, Batch: 17000, Train NLL: 0.8744, Train Acc:0.6250\n",
      "Epoch: 36, Batch: 18000, Train NLL: 0.4368, Train Acc:0.9375\n",
      "Epoch: 36, Batch: 19000, Train NLL: 0.7162, Train Acc:0.6875\n",
      "Epoch: 36, Batch: 20000, Train NLL: 0.5355, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 21000, Train NLL: 0.9146, Train Acc:0.5625\n",
      "Epoch: 36, Batch: 22000, Train NLL: 0.5872, Train Acc:0.8125\n",
      "Epoch: 36, Batch: 23000, Train NLL: 0.4855, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 24000, Train NLL: 0.5604, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 25000, Train NLL: 0.5187, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 26000, Train NLL: 0.3416, Train Acc:0.9375\n",
      "Epoch: 36, Batch: 27000, Train NLL: 0.5055, Train Acc:0.8125\n",
      "Epoch: 36, Batch: 28000, Train NLL: 0.6413, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 29000, Train NLL: 0.8271, Train Acc:0.6250\n",
      "Epoch: 36, Batch: 30000, Train NLL: 0.3563, Train Acc:0.8750\n",
      "Epoch: 36, Batch: 31000, Train NLL: 0.7249, Train Acc:0.6875\n",
      "Epoch: 36, Batch: 32000, Train NLL: 0.4580, Train Acc:0.7500\n",
      "Epoch: 36, Batch: 33000, Train NLL: 0.6429, Train Acc:0.6250\n",
      "Epoch: 36, Batch: 34000, Train NLL: 0.8209, Train Acc:0.5625\n",
      "Epoch: 36, Val NLL: 0.6013, Val Acc: 0.7520\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 37, Batch: 0, Train NLL: 0.4038, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 1000, Train NLL: 0.5713, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 2000, Train NLL: 0.4294, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 3000, Train NLL: 0.4435, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 4000, Train NLL: 0.5188, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 5000, Train NLL: 0.8061, Train Acc:0.5625\n",
      "Epoch: 37, Batch: 6000, Train NLL: 0.4148, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 7000, Train NLL: 0.9951, Train Acc:0.6250\n",
      "Epoch: 37, Batch: 8000, Train NLL: 0.6377, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 9000, Train NLL: 0.4551, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 10000, Train NLL: 0.5241, Train Acc:0.6875\n",
      "Epoch: 37, Batch: 11000, Train NLL: 0.6920, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 12000, Train NLL: 0.3436, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 13000, Train NLL: 0.6914, Train Acc:0.6875\n",
      "Epoch: 37, Batch: 14000, Train NLL: 0.5174, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 15000, Train NLL: 0.7710, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 16000, Train NLL: 0.6586, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 17000, Train NLL: 0.5665, Train Acc:0.6875\n",
      "Epoch: 37, Batch: 18000, Train NLL: 0.5868, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 19000, Train NLL: 0.4969, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 20000, Train NLL: 0.5142, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 21000, Train NLL: 0.7283, Train Acc:0.6250\n",
      "Epoch: 37, Batch: 22000, Train NLL: 0.6126, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 23000, Train NLL: 0.5468, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 24000, Train NLL: 0.5628, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 25000, Train NLL: 0.2775, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 26000, Train NLL: 0.6124, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 27000, Train NLL: 0.4270, Train Acc:0.8750\n",
      "Epoch: 37, Batch: 28000, Train NLL: 0.4628, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 29000, Train NLL: 0.6116, Train Acc:0.6875\n",
      "Epoch: 37, Batch: 30000, Train NLL: 0.6382, Train Acc:0.7500\n",
      "Epoch: 37, Batch: 31000, Train NLL: 0.4767, Train Acc:0.8125\n",
      "Epoch: 37, Batch: 32000, Train NLL: 0.7405, Train Acc:0.6875\n",
      "Epoch: 37, Batch: 33000, Train NLL: 0.9220, Train Acc:0.6250\n",
      "Epoch: 37, Batch: 34000, Train NLL: 0.3664, Train Acc:0.8750\n",
      "Epoch: 37, Val NLL: 0.5984, Val Acc: 0.7554\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 38, Batch: 0, Train NLL: 0.6235, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 1000, Train NLL: 0.3729, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 2000, Train NLL: 0.3724, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 3000, Train NLL: 0.5374, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 4000, Train NLL: 0.4956, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 5000, Train NLL: 0.3272, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 6000, Train NLL: 0.4926, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 7000, Train NLL: 0.4629, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 8000, Train NLL: 0.9359, Train Acc:0.5625\n",
      "Epoch: 38, Batch: 9000, Train NLL: 0.3658, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 10000, Train NLL: 0.1993, Train Acc:0.9375\n",
      "Epoch: 38, Batch: 11000, Train NLL: 0.5686, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 12000, Train NLL: 0.7886, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 13000, Train NLL: 0.4725, Train Acc:0.9375\n",
      "Epoch: 38, Batch: 14000, Train NLL: 0.4543, Train Acc:0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38, Batch: 15000, Train NLL: 0.3446, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 16000, Train NLL: 0.4012, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 17000, Train NLL: 0.6096, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 18000, Train NLL: 0.4776, Train Acc:0.8750\n",
      "Epoch: 38, Batch: 19000, Train NLL: 1.0412, Train Acc:0.4375\n",
      "Epoch: 38, Batch: 20000, Train NLL: 0.5343, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 21000, Train NLL: 0.4460, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 22000, Train NLL: 0.8368, Train Acc:0.6250\n",
      "Epoch: 38, Batch: 23000, Train NLL: 0.5507, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 24000, Train NLL: 0.6544, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 25000, Train NLL: 0.4941, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 26000, Train NLL: 0.7067, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 27000, Train NLL: 0.4167, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 28000, Train NLL: 0.3521, Train Acc:0.9375\n",
      "Epoch: 38, Batch: 29000, Train NLL: 0.6462, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 30000, Train NLL: 0.7063, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 31000, Train NLL: 0.5865, Train Acc:0.6875\n",
      "Epoch: 38, Batch: 32000, Train NLL: 0.5618, Train Acc:0.8125\n",
      "Epoch: 38, Batch: 33000, Train NLL: 0.4088, Train Acc:0.7500\n",
      "Epoch: 38, Batch: 34000, Train NLL: 0.5709, Train Acc:0.8125\n",
      "Epoch: 38, Val NLL: 0.5969, Val Acc: 0.7554\n",
      "LR = 0.025\n",
      "WROTE MODEL\n",
      "Epoch: 39, Batch: 0, Train NLL: 0.6162, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 1000, Train NLL: 0.7469, Train Acc:0.5625\n",
      "Epoch: 39, Batch: 2000, Train NLL: 0.7940, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 3000, Train NLL: 0.6246, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 4000, Train NLL: 0.5652, Train Acc:0.6250\n",
      "Epoch: 39, Batch: 5000, Train NLL: 0.6233, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 6000, Train NLL: 0.3151, Train Acc:0.8750\n",
      "Epoch: 39, Batch: 7000, Train NLL: 0.4938, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 8000, Train NLL: 0.5599, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 9000, Train NLL: 0.7847, Train Acc:0.5625\n",
      "Epoch: 39, Batch: 10000, Train NLL: 0.8657, Train Acc:0.5000\n",
      "Epoch: 39, Batch: 11000, Train NLL: 0.7117, Train Acc:0.5625\n",
      "Epoch: 39, Batch: 12000, Train NLL: 0.4724, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 13000, Train NLL: 0.6556, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 14000, Train NLL: 0.3733, Train Acc:0.8750\n",
      "Epoch: 39, Batch: 15000, Train NLL: 0.6299, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 16000, Train NLL: 0.4343, Train Acc:0.8750\n",
      "Epoch: 39, Batch: 17000, Train NLL: 0.7481, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 18000, Train NLL: 0.4106, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 19000, Train NLL: 0.9785, Train Acc:0.5625\n",
      "Epoch: 39, Batch: 20000, Train NLL: 0.7562, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 21000, Train NLL: 0.6006, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 22000, Train NLL: 0.5366, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 23000, Train NLL: 0.5473, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 24000, Train NLL: 0.5860, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 25000, Train NLL: 0.6011, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 26000, Train NLL: 0.6665, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 27000, Train NLL: 0.6789, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 28000, Train NLL: 0.4109, Train Acc:0.9375\n",
      "Epoch: 39, Batch: 29000, Train NLL: 0.4835, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 30000, Train NLL: 0.5855, Train Acc:0.8125\n",
      "Epoch: 39, Batch: 31000, Train NLL: 0.7336, Train Acc:0.6875\n",
      "Epoch: 39, Batch: 32000, Train NLL: 0.7244, Train Acc:0.5000\n",
      "Epoch: 39, Batch: 33000, Train NLL: 0.4792, Train Acc:0.7500\n",
      "Epoch: 39, Batch: 34000, Train NLL: 0.5858, Train Acc:0.8125\n",
      "Epoch: 39, Val NLL: 0.6021, Val Acc: 0.7546\n",
      "LR = 0.025\n",
      "Epoch: 40, Batch: 0, Train NLL: 0.3904, Train Acc:0.9375\n",
      "Epoch: 40, Batch: 1000, Train NLL: 0.3853, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 2000, Train NLL: 0.8566, Train Acc:0.6875\n",
      "Epoch: 40, Batch: 3000, Train NLL: 0.7797, Train Acc:0.6250\n",
      "Epoch: 40, Batch: 4000, Train NLL: 0.5270, Train Acc:0.6875\n",
      "Epoch: 40, Batch: 5000, Train NLL: 0.5530, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 6000, Train NLL: 0.4936, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 7000, Train NLL: 0.7027, Train Acc:0.6250\n",
      "Epoch: 40, Batch: 8000, Train NLL: 0.5805, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 9000, Train NLL: 0.4928, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 10000, Train NLL: 0.3656, Train Acc:0.9375\n",
      "Epoch: 40, Batch: 11000, Train NLL: 0.6247, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 12000, Train NLL: 0.5366, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 13000, Train NLL: 0.1845, Train Acc:1.0000\n",
      "Epoch: 40, Batch: 14000, Train NLL: 0.7764, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 15000, Train NLL: 0.8838, Train Acc:0.6875\n",
      "Epoch: 40, Batch: 16000, Train NLL: 0.6870, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 17000, Train NLL: 0.4932, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 18000, Train NLL: 0.7511, Train Acc:0.6250\n",
      "Epoch: 40, Batch: 19000, Train NLL: 0.9313, Train Acc:0.5000\n",
      "Epoch: 40, Batch: 20000, Train NLL: 0.2589, Train Acc:0.9375\n",
      "Epoch: 40, Batch: 21000, Train NLL: 0.5378, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 22000, Train NLL: 0.4828, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 23000, Train NLL: 0.4292, Train Acc:0.9375\n",
      "Epoch: 40, Batch: 24000, Train NLL: 0.6754, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 25000, Train NLL: 0.6133, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 26000, Train NLL: 0.8644, Train Acc:0.6875\n",
      "Epoch: 40, Batch: 27000, Train NLL: 0.2046, Train Acc:1.0000\n",
      "Epoch: 40, Batch: 28000, Train NLL: 0.7017, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 29000, Train NLL: 0.3006, Train Acc:0.8750\n",
      "Epoch: 40, Batch: 30000, Train NLL: 0.5602, Train Acc:0.8125\n",
      "Epoch: 40, Batch: 31000, Train NLL: 0.8653, Train Acc:0.5625\n",
      "Epoch: 40, Batch: 32000, Train NLL: 0.5506, Train Acc:0.8750\n",
      "Epoch: 40, Batch: 33000, Train NLL: 0.5977, Train Acc:0.7500\n",
      "Epoch: 40, Batch: 34000, Train NLL: 0.4335, Train Acc:0.9375\n",
      "Epoch: 40, Val NLL: 0.6028, Val Acc: 0.7531\n",
      "LR = 0.025\n",
      "Epoch: 41, Batch: 0, Train NLL: 0.3642, Train Acc:0.8125\n",
      "Epoch: 41, Batch: 1000, Train NLL: 0.5354, Train Acc:0.8125\n",
      "Epoch: 41, Batch: 2000, Train NLL: 0.7169, Train Acc:0.7500\n",
      "Epoch: 41, Batch: 3000, Train NLL: 1.3376, Train Acc:0.5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e7b7803ec0c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEP1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFI1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mED1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mED1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEP1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFI1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFI1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mED1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mED1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-df0dabf1c5c4>\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(e, train_iter, EP1, F1, G1, H1, criterion, optimizer, intra, dist, FI1, ED1)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_loss = 1e8\n",
    "intra = True\n",
    "\n",
    "if intra:\n",
    "    dist = 10\n",
    "    num_embeddings = dist + 1\n",
    "    embedding_dim = 1\n",
    "    FI1 = FeedForwardFIntra(hidden_size1, hidden_size1, hidden_size1).cuda()\n",
    "    ED1 = EmbedDist(num_embeddings, embedding_dim).cuda()\n",
    "    F1 = FeedForwardF(hidden_size1 * 2, hidden_size1, hidden_size1).cuda()\n",
    "    G1 = FeedForwardG(hidden_size2 * 2, hidden_size1, hidden_size1).cuda()\n",
    "else:\n",
    "    dist = None    \n",
    "    FI1 = None\n",
    "    ED1 = None\n",
    "    F1 = FeedForwardF(hidden_size1, hidden_size1, hidden_size1).cuda()\n",
    "    G1 = FeedForwardG(hidden_size2, hidden_size1, hidden_size1).cuda()\n",
    "\n",
    "EP1 = EmbedProject(weights, embed_size, hidden_size1).cuda()\n",
    "H1 = FeedForwardH(hidden_size2, hidden_size1, output_size).cuda()\n",
    "\n",
    "parameters = [param for param in EP1.parameters()] # embed, lnr, bias\n",
    "parameters.extend([param for param in F1.parameters()]) # lnr1, bias1, lnr2, bias2\n",
    "parameters.extend([param for param in G1.parameters()]) # lnr1, bias1, lnr2, bias2\n",
    "parameters.extend([param for param in H1.parameters()]) # lnr1, bias1, lnr2, bias2, lnr3, bias3\n",
    "if intra:\n",
    "    parameters.extend([param for param in FI1.parameters()]) # lnr1, bias1, lnr2, bias2\n",
    "    parameters.extend([param for param in ED1.parameters()]) # embed\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(parameters, lr=0.025, initial_accumulator_value=0.1)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", patience=4)\n",
    "\n",
    "for e in range(100):\n",
    "    training_loop(e, train_iter, EP1, F1, G1, H1, criterion, optimizer, intra=intra, dist=dist, FI1=FI1, ED1=ED1)\n",
    "    loss = validation_loop(e, val_iter, EP1, F1, G1, H1, criterion, intra=intra, dist=dist, FI1=FI1, ED1=ED1)\n",
    "    scheduler.step(loss)\n",
    "    print('LR = {}'.format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "    if loss < best_loss:\n",
    "        torch.save(EP1.state_dict(),'best_EP1_intra.pt')\n",
    "        torch.save(F1.state_dict(),'best_F1_intra.pt')\n",
    "        torch.save(G1.state_dict(),'best_G1_intra.pt')\n",
    "        torch.save(H1.state_dict(),'best_H1_intra.pt')\n",
    "        best_loss = loss\n",
    "        print('WROTE MODEL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ED1.state_dict(),'best_ED1_intra.pt')\n",
    "torch.save(FI1.state_dict(),'best_FI1_intra.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
